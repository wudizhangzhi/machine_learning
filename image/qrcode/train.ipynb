{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Github\\machine_learning\\image\\qrcode\\models\\cnn_ctc.py:64: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"th..., outputs=Tensor(\"so...)`\n",
      "  base_model = Model(input=input_data, output=y_pred)\n"
     ]
    }
   ],
   "source": [
    "from captcha_utils.generator import *\n",
    "from models.cnn_ctc import *\n",
    "\n",
    "\n",
    "train_path = 'E:\\\\traindata\\\\captcha_origin\\\\train'\n",
    "validate_path = 'E:\\\\traindata\\\\captcha_origin\\\\test'\n",
    "img_w = 200\n",
    "img_h = 60\n",
    "channel = 1\n",
    "downsample_factor = 4\n",
    "\n",
    "\n",
    "model, test_func = icp_model()\n",
    "# image_gen = TextImageGenerator(train_path, validate_path, img_w, img_h, channel, downsample_factor)\n",
    "# 使用随机的训练集\n",
    "image_gen = RandomTextImageGenerator(train_path, validate_path, img_w, img_h, channel, downsample_factor)\n",
    "\n",
    "# 测试\n",
    "# test, _ = next(image_gen.get_next_train(10))\n",
    "# test, _ = next(image_gen.get_next_val(5))\n",
    "# x_input = test['the_input']\n",
    "# print(x_input.shape)\n",
    "# print(image_gen.cur_train_idx)\n",
    "# print(image_gen.cur_vald_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.callbacks\n",
    "import datetime\n",
    "\n",
    "class VizCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, run_name, test_func, text_img_gen, output_dir, num_display_words=6):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            output_dir, run_name)\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        acc_ratio = 0\n",
    "        if epoch % 10 == 0:  # 每10个周期计算一次正确率\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            res = decode_batch(self.test_func, TextImageGenerator.labels_to_text, word_batch['the_input'])\n",
    "            acc = 0\n",
    "            total = word_batch['the_input'].shape[0]\n",
    "            for i in range(total):\n",
    "                if word_batch['source_str'][i].lower() == res[i].lower():\n",
    "                    acc += 1\n",
    "            acc_ratio = 100 * acc / total\n",
    "            print('正确率: %0.5f' % acc_ratio)\n",
    "        if acc_ratio > 50 or epoch % 100 == 0 :\n",
    "            self.model.save_weights(os.path.join(self.output_dir, 'weights%02d_acc_%0.5f.h5' % (epoch, acc_ratio)))\n",
    "        word_batch = next(self.text_img_gen)[0]\n",
    "        res = decode_batch(self.test_func, TextImageGenerator.labels_to_text, word_batch['the_input'][0:self.num_display_words])\n",
    "        if word_batch['the_input'][0].shape[0] < 256:\n",
    "            cols = 2\n",
    "        else:\n",
    "            cols = 1\n",
    "        for i in range(self.num_display_words):\n",
    "            plt.subplot(self.num_display_words // cols, cols, i + 1)\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                the_input = word_batch['the_input'][i, 0, :, :]\n",
    "            else:\n",
    "                the_input = word_batch['the_input'][i, :, :, 0]\n",
    "            plt.imshow(the_input, cmap='Greys_r')\n",
    "            plt.xlabel('T = \\'%s\\' Decoed = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "        plt.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n",
    "        plt.close()\n",
    "\n",
    "        \n",
    "vic_gen = RandomTextImageGenerator(train_path, validate_path, img_w, img_h, channel, downsample_factor)\n",
    "vic = VizCallback(datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S'), test_func, vic_gen.get_next_val(), \n",
    "                  output_dir='E:\\\\Github\\\\machine_learning\\\\image\\\\qrcode\\\\logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/501\n",
      "100/100 [==============================] - 44s 438ms/step - loss: 0.4000 - val_loss: 4.9049\n",
      "正确率: 38.00000\n",
      "Epoch 2/501\n",
      "100/100 [==============================] - 40s 399ms/step - loss: 0.4448 - val_loss: 4.7388\n",
      "Epoch 3/501\n",
      "100/100 [==============================] - 41s 408ms/step - loss: 0.4506 - val_loss: 4.8401\n",
      "Epoch 4/501\n",
      "100/100 [==============================] - 40s 404ms/step - loss: 0.4471 - val_loss: 4.8514\n",
      "Epoch 5/501\n",
      "100/100 [==============================] - 41s 405ms/step - loss: 0.4499 - val_loss: 4.6089\n",
      "Epoch 6/501\n",
      "100/100 [==============================] - 41s 405ms/step - loss: 0.4313 - val_loss: 4.7706\n",
      "Epoch 7/501\n",
      "100/100 [==============================] - 41s 405ms/step - loss: 0.4487 - val_loss: 5.1239\n",
      "Epoch 8/501\n",
      "100/100 [==============================] - 40s 404ms/step - loss: 0.4518 - val_loss: 4.5652\n",
      "Epoch 9/501\n",
      "100/100 [==============================] - 41s 406ms/step - loss: 0.4329 - val_loss: 4.6086\n",
      "Epoch 10/501\n",
      "100/100 [==============================] - 41s 406ms/step - loss: 0.4427 - val_loss: 4.6680\n",
      "Epoch 11/501\n",
      "100/100 [==============================] - 40s 401ms/step - loss: 0.4519 - val_loss: 4.8888\n",
      "正确率: 41.00000\n",
      "Epoch 12/501\n",
      "100/100 [==============================] - 40s 397ms/step - loss: 0.4199 - val_loss: 4.8597\n",
      "Epoch 13/501\n",
      "100/100 [==============================] - 40s 400ms/step - loss: 0.4271 - val_loss: 4.5694\n",
      "Epoch 14/501\n",
      "100/100 [==============================] - 40s 400ms/step - loss: 0.4235 - val_loss: 4.5106\n",
      "Epoch 15/501\n",
      "100/100 [==============================] - 40s 400ms/step - loss: 0.4489 - val_loss: 4.5440\n",
      "Epoch 16/501\n",
      "100/100 [==============================] - 41s 407ms/step - loss: 0.4640 - val_loss: 5.0410\n",
      "Epoch 17/501\n",
      "100/100 [==============================] - 40s 404ms/step - loss: 0.4489 - val_loss: 4.5090\n",
      "Epoch 18/501\n",
      "100/100 [==============================] - 40s 400ms/step - loss: 0.4476 - val_loss: 4.6775\n",
      "Epoch 19/501\n",
      "100/100 [==============================] - 40s 404ms/step - loss: 0.4287 - val_loss: 4.7956\n",
      "Epoch 20/501\n",
      "100/100 [==============================] - 40s 404ms/step - loss: 0.4341 - val_loss: 4.9368\n",
      "Epoch 21/501\n",
      "100/100 [==============================] - 40s 399ms/step - loss: 0.4406 - val_loss: 4.5051\n",
      "正确率: 47.00000\n",
      "Epoch 22/501\n",
      "100/100 [==============================] - 40s 399ms/step - loss: 0.4399 - val_loss: 4.4579\n",
      "Epoch 23/501\n",
      "100/100 [==============================] - 40s 401ms/step - loss: 0.4620 - val_loss: 4.4800\n",
      "Epoch 24/501\n",
      "100/100 [==============================] - 40s 399ms/step - loss: 0.4103 - val_loss: 5.0907\n",
      "Epoch 25/501\n",
      "100/100 [==============================] - 40s 399ms/step - loss: 0.4547 - val_loss: 4.5401\n",
      "Epoch 26/501\n",
      "100/100 [==============================] - 41s 407ms/step - loss: 0.4287 - val_loss: 4.5718\n",
      "Epoch 27/501\n",
      "100/100 [==============================] - 41s 405ms/step - loss: 0.4564 - val_loss: 5.1802\n",
      "Epoch 28/501\n",
      "100/100 [==============================] - 40s 401ms/step - loss: 0.4195 - val_loss: 4.6667\n",
      "Epoch 29/501\n",
      "100/100 [==============================] - 40s 399ms/step - loss: 0.4257 - val_loss: 4.9017\n",
      "Epoch 30/501\n",
      "100/100 [==============================] - 40s 400ms/step - loss: 0.4017 - val_loss: 4.5116\n",
      "Epoch 31/501\n",
      "100/100 [==============================] - 40s 402ms/step - loss: 0.4403 - val_loss: 4.7111\n",
      "正确率: 41.00000\n",
      "Epoch 32/501\n",
      "100/100 [==============================] - 40s 397ms/step - loss: 0.4615 - val_loss: 4.5331\n",
      "Epoch 33/501\n",
      "100/100 [==============================] - 41s 408ms/step - loss: 0.3942 - val_loss: 4.8133\n",
      "Epoch 34/501\n",
      "100/100 [==============================] - 43s 428ms/step - loss: 0.4266 - val_loss: 5.0103\n",
      "Epoch 35/501\n",
      " 52/100 [==============>...............] - ETA: 18s - loss: 0.4232"
     ]
    }
   ],
   "source": [
    "callbacks = [vic]\n",
    "train(model, image_gen.get_next_train(100), image_gen.get_next_val(200), callbacks=callbacks, epochs=501, \n",
    "      weight='E:\\\\Github\\\\machine_learning\\\\image\\\\qrcode\\\\logs\\\\2019_05_28_01_33_41\\\\weights500_acc_37.00000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from captcha_utils.icp_factory import *\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
