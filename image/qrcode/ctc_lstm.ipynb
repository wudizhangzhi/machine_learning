{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import codecs\n",
    "import re\n",
    "import datetime\n",
    "# import cairocffi as cairo\n",
    "# import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "# import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n",
    "import pathlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 60, 200, 1)\n",
      "[[[[0.89019608]\n",
      "   [0.89019608]\n",
      "   [0.89019608]]\n",
      "\n",
      "  [[0.89019608]\n",
      "   [0.89019608]\n",
      "   [0.89019608]]\n",
      "\n",
      "  [[0.89019608]\n",
      "   [0.89019608]\n",
      "   [0.89019608]]]\n",
      "\n",
      "\n",
      " [[[0.81960784]\n",
      "   [0.81960784]\n",
      "   [0.81960784]]\n",
      "\n",
      "  [[0.81960784]\n",
      "   [0.81960784]\n",
      "   [0.81960784]]\n",
      "\n",
      "  [[0.81960784]\n",
      "   [0.81960784]\n",
      "   [0.81960784]]]\n",
      "\n",
      "\n",
      " [[[0.77254902]\n",
      "   [0.77254902]\n",
      "   [0.77254902]]\n",
      "\n",
      "  [[0.77254902]\n",
      "   [0.77254902]\n",
      "   [0.77254902]]\n",
      "\n",
      "  [[0.77254902]\n",
      "   [0.77254902]\n",
      "   [0.77254902]]]]\n",
      "[[12.  8.  7.  7. 32. 19.]\n",
      " [11. 19. 35. 21. 31.  8.]\n",
      " [ 3.  2. 11. 31.  3. 27.]]\n",
      "[[48.]\n",
      " [48.]\n",
      " [48.]]\n",
      "[[6.]\n",
      " [6.]\n",
      " [6.]]\n",
      "['c877wj', 'bjzlv8', '32bv3r']\n"
     ]
    }
   ],
   "source": [
    "from icp_factory import GenCaptcha\n",
    "\n",
    "gencaptcha = GenCaptcha()\n",
    "\n",
    "class TextImageGenerator(keras.callbacks.Callback):\n",
    "    # 所有可能字符\n",
    "    LABELS = '0123456789abcdefghijklmnopqrstuvwxyz '\n",
    "    \n",
    "    def __init__(self, train_path, validate_path, img_w, img_h, channel, downsample_factor, absolute_max_string_len=6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            train_path: 训练数据路径\n",
    "            validate_path: 验证图片路径\n",
    "            img_w:\n",
    "            img_h:\n",
    "            downsample_factor: TODO 未知\n",
    "            absolute_max_string_len: 最大字符串长度\n",
    "        \"\"\"\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.channel = channel\n",
    "        self.train_path = train_path\n",
    "        self.validate_path = validate_path\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.blank_label = self.get_output_size() - 1\n",
    "        self.absolute_max_string_len = absolute_max_string_len\n",
    "        # 数据\n",
    "        self.train_imgs = self.get_all_imgs(self.train_path)\n",
    "        self.validate_imgs = self.get_all_imgs(self.validate_path)\n",
    "        self.cur_idx = 0\n",
    "        \n",
    "        np.random.shuffle(self.train_imgs)\n",
    "        np.random.shuffle(self.validate_imgs)\n",
    "    \n",
    "    def get_all_imgs(self, path):\n",
    "#         p = pathlib.Path(path)\n",
    "        # jpg or png\n",
    "#         return list([str(i) for i in p.glob('*.jpg')])\n",
    "        return [os.path.join(path, i) for i in os.listdir(path)]\n",
    "    \n",
    "    def get_output_size(self):\n",
    "        return len(self.LABELS) + 1\n",
    "    \n",
    "    def char2idx(self, char):\n",
    "        idx = self.LABELS.find(char.lower())\n",
    "        return idx if idx != -1 else self.blank_label\n",
    "    \n",
    "    @staticmethod\n",
    "    def labels_to_text(labels):\n",
    "        ret = []\n",
    "        for c in labels:\n",
    "            if c == len(TextImageGenerator.LABELS):  # CTC Blank\n",
    "                ret.append(\"\")\n",
    "            else:\n",
    "                ret.append(TextImageGenerator.LABELS[c])\n",
    "        return \"\".join(ret)\n",
    "    \n",
    "    def path2matrix(self, path):\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, w, h, channel)\n",
    "        \"\"\"\n",
    "        img = cv2.imread(path)\n",
    "        img = self.formatCaptcha(img)\n",
    "        return img\n",
    "    \n",
    "    def formatCaptcha(self, img):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img/ 255.\n",
    "#         img_transpose = np.einsum('hw->wh', img)\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        return img\n",
    "    \n",
    "    def _get_one_captcha(self):\n",
    "        captcha, text = gencaptcha.gen_one()\n",
    "        return captcha, text\n",
    "\n",
    "    def get_next_batch(self, paths, batch_size=32):\n",
    "        def get_label(img_path):\n",
    "            \"\"\"\n",
    "            获取验证码对应的字符串\n",
    "            \"\"\"\n",
    "            return os.path.basename(img_path).split('.')[0].lower()\n",
    "        i = 0\n",
    "#         X_data = np.zeros((batch_size, self.img_w, self.img_h, self.channel))\n",
    "        X_data = np.zeros((batch_size, self.img_h, self.img_w, self.channel))\n",
    "        labels = np.zeros((batch_size, self.absolute_max_string_len))\n",
    "        input_length = np.zeros([batch_size, 1])\n",
    "        label_length = np.zeros([batch_size, 1])\n",
    "        source_str = []\n",
    "        while i < batch_size:\n",
    "            if self.cur_idx >= len(paths):\n",
    "                # 归零，洗牌\n",
    "                self.cur_idx = 0\n",
    "                np.random.shuffle(paths)\n",
    "#             img_path = paths[self.cur_idx]\n",
    "#             label_text = get_label(img_path)\n",
    "            # 使用自动生成的\n",
    "            captcha, label_text = self._get_one_captcha()\n",
    "#             X_data[i, :] = self.path2matrix(img_path)\n",
    "            X_data[i, :] = self.formatCaptcha(captcha)\n",
    "            input_length[i] = self.img_w // self.downsample_factor - 2\n",
    "            label_length[i] = len(label_text)\n",
    "            labels[i] = [self.char2idx(char) for char in label_text]\n",
    "            source_str.append(label_text)\n",
    "            \n",
    "            self.cur_idx += 1\n",
    "            i += 1\n",
    "            \n",
    "        inputs = {\n",
    "              'the_input': X_data,\n",
    "              'the_labels': labels,\n",
    "              'input_length': input_length,\n",
    "              'label_length': label_length,\n",
    "              'source_str': source_str  # used for visualization only\n",
    "        }\n",
    "        outputs = {'ctc': np.zeros([batch_size])}\n",
    "        return (inputs, outputs)\n",
    "            \n",
    "    def get_next_train(self, batch_size=32):\n",
    "        while True:\n",
    "            yield self.get_next_batch(self.train_imgs, batch_size)\n",
    "    \n",
    "    def get_next_val(self, batch_size=100):\n",
    "        while True:\n",
    "            yield self.get_next_batch(self.validate_imgs, batch_size)\n",
    "        \n",
    "\n",
    "\n",
    "train_path = 'E:\\\\traindata\\\\captcha_create\\\\train'\n",
    "validate_path = 'E:\\\\traindata\\\\captcha_create\\\\test'\n",
    "test_img = os.path.join(train_path, '00ARLO.jpg')\n",
    "\n",
    "img_w = 200\n",
    "img_h = 60\n",
    "channel = 1\n",
    "downsample_factor = 4\n",
    "img_gen = TextImageGenerator(train_path, validate_path, img_w, img_h, channel, downsample_factor)\n",
    "ret_input, ret_output = next(img_gen.get_next_train(3))\n",
    "ret_input, ret_output = next(img_gen.get_next_train(3))\n",
    "print(ret_input['the_input'].shape)\n",
    "print(ret_input['the_input'][:3, :3, :3])\n",
    "print(ret_input['the_labels'])\n",
    "print(ret_input['input_length'])\n",
    "print(ret_input['label_length'])\n",
    "print(ret_input['source_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 60, 200, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 60, 200, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 30, 100, 16)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 30, 100, 16)  2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 15, 50, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 240)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 50, 32)       7712        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 50, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 50, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 50, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 50, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 50, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 50, 38)       38950       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 50, 38)       0           dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,872,182\n",
      "Trainable params: 4,872,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\ipykernel_launcher.py:55: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"th..., outputs=Tensor(\"so...)`\n"
     ]
    }
   ],
   "source": [
    "conv_filters = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "rnn_size = 512\n",
    "minibatch_size = 32\n",
    "OUTPUT_DIR = 'E:\\\\Workplace\\\\bdzh\\\\MachineLearning\\\\SmallCaptcha\\\\image_ocr'\n",
    "\n",
    "\n",
    "# the actual loss calc occurs here despite it not being\n",
    "# an internal Keras loss function\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (channel, img_w, img_h)\n",
    "else:\n",
    "#     input_shape = (img_w, img_h, channel)\n",
    "    input_shape = (img_h, img_w, channel)\n",
    "\n",
    "act = 'relu'\n",
    "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv1')(input_data)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv2')(inner)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "# cuts down input size going into RNN:\n",
    "inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "# Two layers of bidirectional GRUs\n",
    "# GRU seems to work as well, if not better than LSTM:\n",
    "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "gru1_merged = add([gru_1, gru_1b])\n",
    "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "# transforms RNN output to character activations:\n",
    "inner = Dense(img_gen.get_output_size(), kernel_initializer='he_normal',\n",
    "              name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "base_model = Model(input=input_data, output=y_pred)\n",
    "base_model.summary()\n",
    "\n",
    "labels = Input(name='the_labels', shape=[img_gen.absolute_max_string_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "# Keras doesn't currently support loss funcs with extra parameters\n",
    "# so CTC loss is implemented in a lambda layer\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "# clipnorm seems to speeds up convergence\n",
    "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VizCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, run_name, test_func, text_img_gen, num_display_words=6):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            OUTPUT_DIR, run_name)\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            num_proc = min(word_batch['the_input'].shape[0], num_left)\n",
    "            decoded_res = decode_batch(self.test_func, word_batch['the_input'][0:num_proc])\n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j], word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(word_batch['source_str'][j])\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance: %.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 10 == 0: # 每10个周期计算一次正确率\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            res = decode_batch(self.test_func, word_batch['the_input'])\n",
    "            if word_batch['the_input'][0].shape[0] < 256:\n",
    "                cols = 2\n",
    "            else:\n",
    "                cols = 1\n",
    "            acc = 0\n",
    "            total = word_batch['the_input'].shape[0]\n",
    "            for i in range(total):\n",
    "                if word_batch['source_str'][i].lower() == res[i].lower():\n",
    "                    acc += 1\n",
    "            acc_ratio = 100 * acc / total\n",
    "            print('正确率: %0.5f' % acc_ratio)\n",
    "            if acc_ratio > 50:\n",
    "                self.model.save_weights(os.path.join(self.output_dir, 'weights%02d_acc_%0.5f.h5' % (epoch, acc_ratio)))\n",
    "        word_batch = next(self.text_img_gen)[0]\n",
    "        res = decode_batch(self.test_func, word_batch['the_input'][0:self.num_display_words])\n",
    "        if word_batch['the_input'][0].shape[0] < 256:\n",
    "            cols = 2\n",
    "        else:\n",
    "            cols = 1\n",
    "        for i in range(self.num_display_words):\n",
    "            plt.subplot(self.num_display_words // cols, cols, i + 1)\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                the_input = word_batch['the_input'][i, 0, :, :]\n",
    "            else:\n",
    "                the_input = word_batch['the_input'][i, :, :, 0]\n",
    "            plt.imshow(the_input, cmap='Greys_r')\n",
    "            plt.xlabel('T = \\'%s\\' Decoed = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "        plt.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n",
    "        plt.close()\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = TextImageGenerator.labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def evaluate(test_func, img_gen, batch_size=5):\n",
    "    correct_count = 0\n",
    "    img_gen = img_gen.get_next_val(batch_size=batch_size)\n",
    "    _x, _ctc = next(img_gen)\n",
    "    for i in range(batch_size):\n",
    "        test_X = _x['the_input'][i]\n",
    "        test_c = _x['source_str'][i]\n",
    "        test_X = np.expand_dims(test_X, axis=-1)\n",
    "        result = decode_batch(test_func, test_X)[0]\n",
    "        try:\n",
    "            if test_c.lower() == result.lower():\n",
    "                correct_count += 1\n",
    "                # print(\"[INFO] actual: %s, predict: %s\" % (test_c, result))\n",
    "            else:\n",
    "                print(\"[ERROR] actual: %s, predict: %s\" % (test_c, result))\n",
    "        except Exception as e:\n",
    "            print(e.message)\n",
    "    print(\"Accuracy: %.2f%%\" % ((float(correct_count) / batch_size) * 100))\n",
    "    \n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    def __init__(self, test_func, text_img_gen):\n",
    "        self.test_func = test_func\n",
    "        self.text_img_gen = text_img_gen\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        evaluate(self.test_func, self.text_img_gen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "100/100 [==============================] - 88s 877ms/step - loss: 22.4953 - val_loss: 22.4608\n",
      "正确率: 0.00000\n",
      "Epoch 2/400\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 22.3769 - val_loss: 22.2498\n",
      "Epoch 3/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 22.1305 - val_loss: 21.9076\n",
      "Epoch 4/400\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 21.8595 - val_loss: 21.7784\n",
      "Epoch 5/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 21.5581 - val_loss: 21.3423\n",
      "Epoch 6/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 21.3541 - val_loss: 21.1599\n",
      "Epoch 7/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 20.9416 - val_loss: 20.6329\n",
      "Epoch 8/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 20.5281 - val_loss: 20.2903\n",
      "Epoch 9/400\n",
      "100/100 [==============================] - 64s 641ms/step - loss: 20.0753 - val_loss: 19.9676\n",
      "Epoch 10/400\n",
      "100/100 [==============================] - 64s 637ms/step - loss: 19.6221 - val_loss: 19.4658\n",
      "Epoch 11/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 19.1719 - val_loss: 19.0101\n",
      "正确率: 0.00000\n",
      "Epoch 12/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 18.7521 - val_loss: 18.5560\n",
      "Epoch 13/400\n",
      "100/100 [==============================] - 64s 635ms/step - loss: 18.3265 - val_loss: 17.9713\n",
      "Epoch 14/400\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 17.6018 - val_loss: 16.8875\n",
      "Epoch 15/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 16.5479 - val_loss: 15.9707\n",
      "Epoch 16/400\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 15.5655 - val_loss: 15.2758\n",
      "Epoch 17/400\n",
      "100/100 [==============================] - 63s 635ms/step - loss: 14.8117 - val_loss: 14.6992\n",
      "Epoch 18/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 14.2216 - val_loss: 13.9388\n",
      "Epoch 19/400\n",
      "100/100 [==============================] - 64s 636ms/step - loss: 13.5396 - val_loss: 13.2459\n",
      "Epoch 20/400\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 12.9283 - val_loss: 12.6476\n",
      "Epoch 21/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 12.3190 - val_loss: 12.2652\n",
      "正确率: 0.00000\n",
      "Epoch 22/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 11.7130 - val_loss: 11.5472\n",
      "Epoch 23/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 11.2131 - val_loss: 10.9258\n",
      "Epoch 24/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 10.7629 - val_loss: 10.5049\n",
      "Epoch 25/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 10.3546 - val_loss: 10.2804\n",
      "Epoch 26/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 9.9400 - val_loss: 9.6309\n",
      "Epoch 27/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 9.4754 - val_loss: 9.2949\n",
      "Epoch 28/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 9.1836 - val_loss: 8.9571\n",
      "Epoch 29/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 8.9128 - val_loss: 8.4365\n",
      "Epoch 30/400\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 8.5838 - val_loss: 8.4150\n",
      "Epoch 31/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 8.2222 - val_loss: 7.9696\n",
      "正确率: 1.00000\n",
      "Epoch 32/400\n",
      "100/100 [==============================] - 62s 619ms/step - loss: 8.0054 - val_loss: 7.7933\n",
      "Epoch 33/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 7.6825 - val_loss: 7.6559\n",
      "Epoch 34/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 7.3787 - val_loss: 7.1451\n",
      "Epoch 35/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 7.2243 - val_loss: 6.9891\n",
      "Epoch 36/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 6.8555 - val_loss: 6.5801\n",
      "Epoch 37/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 6.5664 - val_loss: 6.3601\n",
      "Epoch 38/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 6.4837 - val_loss: 6.2542\n",
      "Epoch 39/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 6.1980 - val_loss: 6.1222\n",
      "Epoch 40/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 5.9625 - val_loss: 5.9543\n",
      "Epoch 41/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 5.8077 - val_loss: 5.6527\n",
      "正确率: 18.00000\n",
      "Epoch 42/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 5.5449 - val_loss: 5.4782\n",
      "Epoch 43/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 5.4748 - val_loss: 5.6703\n",
      "Epoch 44/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 5.2794 - val_loss: 5.2308\n",
      "Epoch 45/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 5.1757 - val_loss: 4.9042\n",
      "Epoch 46/400\n",
      "100/100 [==============================] - 64s 638ms/step - loss: 4.9266 - val_loss: 4.7198\n",
      "Epoch 47/400\n",
      "100/100 [==============================] - 64s 639ms/step - loss: 4.8847 - val_loss: 4.7696\n",
      "Epoch 48/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 4.6913 - val_loss: 4.4746\n",
      "Epoch 49/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 4.6002 - val_loss: 4.4755\n",
      "Epoch 50/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 4.4086 - val_loss: 4.3136\n",
      "Epoch 51/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 4.3017 - val_loss: 4.1468\n",
      "正确率: 26.00000\n",
      "Epoch 52/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 4.2297 - val_loss: 4.1164\n",
      "Epoch 53/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 4.1701 - val_loss: 4.0470\n",
      "Epoch 54/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 4.0735 - val_loss: 4.1526\n",
      "Epoch 55/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 3.8563 - val_loss: 3.8913\n",
      "Epoch 56/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 3.7811 - val_loss: 3.7951\n",
      "Epoch 57/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 3.6876 - val_loss: 3.5552\n",
      "Epoch 58/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 3.6509 - val_loss: 3.7015\n",
      "Epoch 59/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 3.5748 - val_loss: 3.6802\n",
      "Epoch 60/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 3.5582 - val_loss: 3.5120\n",
      "Epoch 61/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 3.4092 - val_loss: 3.3999\n",
      "正确率: 36.00000\n",
      "Epoch 62/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 3.3087 - val_loss: 3.2338\n",
      "Epoch 63/400\n",
      "100/100 [==============================] - 63s 635ms/step - loss: 3.2827 - val_loss: 3.0916\n",
      "Epoch 64/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 3.1341 - val_loss: 2.9791\n",
      "Epoch 65/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 3.1042 - val_loss: 2.9665\n",
      "Epoch 66/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 3.0125 - val_loss: 3.0906\n",
      "Epoch 67/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 2.9870 - val_loss: 3.0495\n",
      "Epoch 68/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 2.8923 - val_loss: 2.7930\n",
      "Epoch 69/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 2.8855 - val_loss: 2.7090\n",
      "Epoch 70/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 2.8308 - val_loss: 2.8763\n",
      "Epoch 71/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 2.7583 - val_loss: 2.9192\n",
      "正确率: 46.00000\n",
      "Epoch 72/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 2.7306 - val_loss: 2.5534\n",
      "Epoch 73/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 2.6413 - val_loss: 2.6755\n",
      "Epoch 74/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 2.6110 - val_loss: 2.7163\n",
      "Epoch 75/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 2.6525 - val_loss: 2.8346\n",
      "Epoch 76/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 2.5185 - val_loss: 2.3822\n",
      "Epoch 77/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 63s 630ms/step - loss: 2.4318 - val_loss: 2.2447\n",
      "Epoch 78/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 2.3249 - val_loss: 2.2628\n",
      "Epoch 79/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 2.3344 - val_loss: 2.3537\n",
      "Epoch 80/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 2.2352 - val_loss: 2.2917\n",
      "Epoch 81/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 2.2004 - val_loss: 2.4512\n",
      "正确率: 41.00000\n",
      "Epoch 82/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 2.1517 - val_loss: 2.0160\n",
      "Epoch 83/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 2.0798 - val_loss: 2.1729\n",
      "Epoch 84/400\n",
      "100/100 [==============================] - 64s 635ms/step - loss: 2.1045 - val_loss: 2.1390\n",
      "Epoch 85/400\n",
      "100/100 [==============================] - 64s 638ms/step - loss: 2.0342 - val_loss: 1.9650\n",
      "Epoch 86/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.9753 - val_loss: 2.0394\n",
      "Epoch 87/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.9857 - val_loss: 1.9286\n",
      "Epoch 88/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.9393 - val_loss: 1.7597\n",
      "Epoch 89/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.9074 - val_loss: 1.8626\n",
      "Epoch 90/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 1.8958 - val_loss: 1.7849\n",
      "Epoch 91/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.8222 - val_loss: 1.8543\n",
      "正确率: 51.00000\n",
      "Epoch 92/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 1.8331 - val_loss: 1.8441\n",
      "Epoch 93/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.8370 - val_loss: 2.1277\n",
      "Epoch 94/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.8064 - val_loss: 1.6767\n",
      "Epoch 95/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.7647 - val_loss: 1.6914\n",
      "Epoch 96/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.7993 - val_loss: 1.6474\n",
      "Epoch 97/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.6767 - val_loss: 1.6317\n",
      "Epoch 98/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.7215 - val_loss: 1.5925\n",
      "Epoch 99/400\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 1.6605 - val_loss: 1.5997\n",
      "Epoch 100/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.6942 - val_loss: 1.7763\n",
      "Epoch 101/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 1.6468 - val_loss: 1.8338\n",
      "正确率: 59.00000\n",
      "Epoch 102/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 1.6649 - val_loss: 1.6682\n",
      "Epoch 103/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 1.6325 - val_loss: 1.5716\n",
      "Epoch 104/400\n",
      "100/100 [==============================] - 63s 635ms/step - loss: 1.6054 - val_loss: 1.5555\n",
      "Epoch 105/400\n",
      "100/100 [==============================] - 64s 635ms/step - loss: 1.5809 - val_loss: 1.4823\n",
      "Epoch 106/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.5733 - val_loss: 1.6460\n",
      "Epoch 107/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.5318 - val_loss: 1.3605\n",
      "Epoch 108/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.5418 - val_loss: 1.4665\n",
      "Epoch 109/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 1.5110 - val_loss: 1.4782\n",
      "Epoch 110/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.4947 - val_loss: 1.3801\n",
      "Epoch 111/400\n",
      "100/100 [==============================] - 65s 646ms/step - loss: 1.4730 - val_loss: 1.4217\n",
      "正确率: 66.00000\n",
      "Epoch 112/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 1.4995 - val_loss: 1.5050\n",
      "Epoch 113/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.4402 - val_loss: 1.3120\n",
      "Epoch 114/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 1.4566 - val_loss: 1.5678\n",
      "Epoch 115/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.4819 - val_loss: 1.3302\n",
      "Epoch 116/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.4468 - val_loss: 1.3890\n",
      "Epoch 117/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.4058 - val_loss: 1.4895\n",
      "Epoch 118/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.4460 - val_loss: 1.2901\n",
      "Epoch 119/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 1.4184 - val_loss: 1.5678\n",
      "Epoch 120/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.3882 - val_loss: 1.3769\n",
      "Epoch 121/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.3519 - val_loss: 1.3020\n",
      "正确率: 69.00000\n",
      "Epoch 122/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 1.3085 - val_loss: 1.2095\n",
      "Epoch 123/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.3686 - val_loss: 1.3740\n",
      "Epoch 124/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.3526 - val_loss: 1.2524\n",
      "Epoch 125/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.3268 - val_loss: 1.2053\n",
      "Epoch 126/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.3601 - val_loss: 1.2789\n",
      "Epoch 127/400\n",
      "100/100 [==============================] - 64s 638ms/step - loss: 1.3317 - val_loss: 1.1859\n",
      "Epoch 128/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.3007 - val_loss: 1.2221\n",
      "Epoch 129/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 1.2714 - val_loss: 1.2888\n",
      "Epoch 130/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 1.2695 - val_loss: 1.1773\n",
      "Epoch 131/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.2462 - val_loss: 1.2924\n",
      "正确率: 65.00000\n",
      "Epoch 132/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 1.2957 - val_loss: 1.0886\n",
      "Epoch 133/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 1.2562 - val_loss: 1.1313\n",
      "Epoch 134/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.2563 - val_loss: 1.1940\n",
      "Epoch 135/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.2213 - val_loss: 1.2742\n",
      "Epoch 136/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.1909 - val_loss: 1.1639\n",
      "Epoch 137/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 1.2365 - val_loss: 1.2187\n",
      "Epoch 138/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 1.1807 - val_loss: 1.1632\n",
      "Epoch 139/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 1.1487 - val_loss: 1.1830\n",
      "Epoch 140/400\n",
      "100/100 [==============================] - 63s 634ms/step - loss: 1.1483 - val_loss: 1.2569\n",
      "Epoch 141/400\n",
      "100/100 [==============================] - 64s 637ms/step - loss: 1.2088 - val_loss: 1.1184\n",
      "正确率: 69.00000\n",
      "Epoch 142/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 1.1777 - val_loss: 1.2249\n",
      "Epoch 143/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 1.1504 - val_loss: 1.1717\n",
      "Epoch 144/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.1381 - val_loss: 1.1051\n",
      "Epoch 145/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 1.1335 - val_loss: 1.1942\n",
      "Epoch 146/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.0852 - val_loss: 1.0872\n",
      "Epoch 147/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 1.1523 - val_loss: 1.0851\n",
      "Epoch 148/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.1107 - val_loss: 1.4089\n",
      "Epoch 149/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.1118 - val_loss: 1.1704\n",
      "Epoch 150/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.1182 - val_loss: 1.1243\n",
      "Epoch 151/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 1.1587 - val_loss: 1.0700\n",
      "正确率: 66.00000\n",
      "Epoch 152/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 1.0916 - val_loss: 1.2157\n",
      "Epoch 153/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 63s 631ms/step - loss: 1.0778 - val_loss: 1.2237\n",
      "Epoch 154/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 1.0717 - val_loss: 1.1260\n",
      "Epoch 155/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 1.0509 - val_loss: 1.0371\n",
      "Epoch 156/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.0826 - val_loss: 1.1503\n",
      "Epoch 157/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 1.0541 - val_loss: 0.9924\n",
      "Epoch 158/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 1.0821 - val_loss: 0.9688\n",
      "Epoch 159/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 1.1149 - val_loss: 1.2519\n",
      "Epoch 160/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.0510 - val_loss: 1.0712\n",
      "Epoch 161/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.0347 - val_loss: 0.9805\n",
      "正确率: 77.00000\n",
      "Epoch 162/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 1.0516 - val_loss: 1.1001\n",
      "Epoch 163/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 1.0612 - val_loss: 1.0465\n",
      "Epoch 164/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 1.0302 - val_loss: 1.0008\n",
      "Epoch 165/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 1.0360 - val_loss: 0.9656\n",
      "Epoch 166/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.9918 - val_loss: 1.0078\n",
      "Epoch 167/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 1.1991 - val_loss: 0.9582\n",
      "Epoch 168/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 1.0146 - val_loss: 1.0309\n",
      "Epoch 169/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.9570 - val_loss: 0.9917\n",
      "Epoch 170/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.9964 - val_loss: 1.1714\n",
      "Epoch 171/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 1.0423 - val_loss: 0.9119\n",
      "正确率: 80.00000\n",
      "Epoch 172/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.9605 - val_loss: 1.0019\n",
      "Epoch 173/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.9995 - val_loss: 0.9856\n",
      "Epoch 174/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 0.9948 - val_loss: 1.0029\n",
      "Epoch 175/400\n",
      "100/100 [==============================] - 63s 633ms/step - loss: 0.9419 - val_loss: 1.0277\n",
      "Epoch 176/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.9960 - val_loss: 0.9056\n",
      "Epoch 177/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 0.9816 - val_loss: 0.9318\n",
      "Epoch 178/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.9586 - val_loss: 1.0461\n",
      "Epoch 179/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.8870 - val_loss: 0.8560\n",
      "Epoch 180/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.9286 - val_loss: 1.0228\n",
      "Epoch 181/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.9482 - val_loss: 0.8423\n",
      "正确率: 70.00000\n",
      "Epoch 182/400\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.9260 - val_loss: 0.8495\n",
      "Epoch 183/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.9182 - val_loss: 0.9990\n",
      "Epoch 184/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.9679 - val_loss: 1.0379\n",
      "Epoch 185/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.9103 - val_loss: 0.9120\n",
      "Epoch 186/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.9070 - val_loss: 0.8557\n",
      "Epoch 187/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.9317 - val_loss: 0.8534\n",
      "Epoch 188/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.8474 - val_loss: 0.9589\n",
      "Epoch 189/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.9070 - val_loss: 0.9054\n",
      "Epoch 190/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.8879 - val_loss: 0.9311\n",
      "Epoch 191/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.8765 - val_loss: 0.9476\n",
      "正确率: 74.00000\n",
      "Epoch 192/400\n",
      "100/100 [==============================] - 61s 615ms/step - loss: 0.9107 - val_loss: 0.8891\n",
      "Epoch 193/400\n",
      "100/100 [==============================] - 62s 620ms/step - loss: 0.8748 - val_loss: 0.8575\n",
      "Epoch 194/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.8630 - val_loss: 0.7653\n",
      "Epoch 195/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.8571 - val_loss: 0.8503\n",
      "Epoch 196/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.8491 - val_loss: 0.8607\n",
      "Epoch 197/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.8640 - val_loss: 0.7946\n",
      "Epoch 198/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.8818 - val_loss: 0.8065\n",
      "Epoch 199/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.8638 - val_loss: 0.8858\n",
      "Epoch 200/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.8767 - val_loss: 0.8524\n",
      "Epoch 201/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.8566 - val_loss: 0.7937\n",
      "正确率: 80.00000\n",
      "Epoch 202/400\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.8757 - val_loss: 0.7987\n",
      "Epoch 203/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.8321 - val_loss: 0.8248\n",
      "Epoch 204/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.8554 - val_loss: 0.8207\n",
      "Epoch 205/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.8246 - val_loss: 0.7654\n",
      "Epoch 206/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.8469 - val_loss: 0.8056\n",
      "Epoch 207/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.8363 - val_loss: 0.8666\n",
      "Epoch 208/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.8405 - val_loss: 0.7988\n",
      "Epoch 209/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.8245 - val_loss: 0.9391\n",
      "Epoch 210/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.8255 - val_loss: 0.7686\n",
      "Epoch 211/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.7844 - val_loss: 0.8599\n",
      "正确率: 83.00000\n",
      "Epoch 212/400\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.7999 - val_loss: 0.7594\n",
      "Epoch 213/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.7491 - val_loss: 0.7585\n",
      "Epoch 214/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.7737 - val_loss: 0.7145\n",
      "Epoch 215/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.7796 - val_loss: 0.7600\n",
      "Epoch 216/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.8282 - val_loss: 0.7088\n",
      "Epoch 217/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.8092 - val_loss: 0.7463\n",
      "Epoch 218/400\n",
      "100/100 [==============================] - 64s 635ms/step - loss: 0.8010 - val_loss: 0.7257\n",
      "Epoch 219/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.7834 - val_loss: 0.7960\n",
      "Epoch 220/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.7922 - val_loss: 0.6901\n",
      "Epoch 221/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.7602 - val_loss: 0.6958\n",
      "正确率: 88.00000\n",
      "Epoch 222/400\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.7630 - val_loss: 0.7496\n",
      "Epoch 223/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.7204 - val_loss: 0.7641\n",
      "Epoch 224/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.7450 - val_loss: 0.7926\n",
      "Epoch 225/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.7434 - val_loss: 0.7880\n",
      "Epoch 226/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.7752 - val_loss: 0.8240\n",
      "Epoch 227/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.7541 - val_loss: 0.7692\n",
      "Epoch 228/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.7671 - val_loss: 0.7811\n",
      "Epoch 229/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 62s 625ms/step - loss: 0.7835 - val_loss: 0.7649\n",
      "Epoch 230/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.7626 - val_loss: 0.7504\n",
      "Epoch 231/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.7094 - val_loss: 0.7550\n",
      "正确率: 75.00000\n",
      "Epoch 232/400\n",
      "100/100 [==============================] - 62s 615ms/step - loss: 0.7232 - val_loss: 0.6876\n",
      "Epoch 233/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.7250 - val_loss: 0.7167\n",
      "Epoch 234/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.7449 - val_loss: 0.7329\n",
      "Epoch 235/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.7292 - val_loss: 0.8047\n",
      "Epoch 236/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.6931 - val_loss: 0.6603\n",
      "Epoch 237/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.7252 - val_loss: 0.7143\n",
      "Epoch 238/400\n",
      "100/100 [==============================] - 62s 620ms/step - loss: 0.7023 - val_loss: 0.6553\n",
      "Epoch 239/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.7008 - val_loss: 0.6497\n",
      "Epoch 240/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.7104 - val_loss: 0.6817\n",
      "Epoch 241/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.7705 - val_loss: 0.7159\n",
      "正确率: 84.00000\n",
      "Epoch 242/400\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.6921 - val_loss: 0.6180\n",
      "Epoch 243/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.7195 - val_loss: 0.7219\n",
      "Epoch 244/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.6928 - val_loss: 0.5803\n",
      "Epoch 245/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.7340 - val_loss: 0.9667\n",
      "Epoch 246/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.7185 - val_loss: 0.5930\n",
      "Epoch 247/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.7134 - val_loss: 0.6641\n",
      "Epoch 248/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.7382 - val_loss: 0.7351\n",
      "Epoch 249/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.7142 - val_loss: 0.6398\n",
      "Epoch 250/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.6988 - val_loss: 0.7134\n",
      "Epoch 251/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.6714 - val_loss: 0.6118\n",
      "正确率: 81.00000\n",
      "Epoch 252/400\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.6970 - val_loss: 0.6068\n",
      "Epoch 253/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.6479 - val_loss: 0.6054\n",
      "Epoch 254/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.6841 - val_loss: 0.6163\n",
      "Epoch 255/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.6545 - val_loss: 0.5867\n",
      "Epoch 256/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.6589 - val_loss: 0.6526\n",
      "Epoch 257/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.6491 - val_loss: 0.6350\n",
      "Epoch 258/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.6541 - val_loss: 0.6461\n",
      "Epoch 259/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.6708 - val_loss: 0.5086\n",
      "Epoch 260/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.6528 - val_loss: 0.6124\n",
      "Epoch 261/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.6656 - val_loss: 0.6094\n",
      "正确率: 87.00000\n",
      "Epoch 262/400\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.6811 - val_loss: 1.0559\n",
      "Epoch 263/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.6666 - val_loss: 0.5567\n",
      "Epoch 264/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.6615 - val_loss: 0.6728\n",
      "Epoch 265/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.6394 - val_loss: 0.6842\n",
      "Epoch 266/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.6893 - val_loss: 0.7342\n",
      "Epoch 267/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.6640 - val_loss: 0.7542\n",
      "Epoch 268/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.6241 - val_loss: 0.6401\n",
      "Epoch 269/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.6188 - val_loss: 0.5942\n",
      "Epoch 270/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.6660 - val_loss: 0.6913\n",
      "Epoch 271/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.6260 - val_loss: 0.6180\n",
      "正确率: 80.00000\n",
      "Epoch 272/400\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.6748 - val_loss: 0.5913\n",
      "Epoch 273/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.6533 - val_loss: 0.6401\n",
      "Epoch 274/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.6243 - val_loss: 0.6589\n",
      "Epoch 275/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.6429 - val_loss: 0.5762\n",
      "Epoch 276/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.6218 - val_loss: 0.6199\n",
      "Epoch 277/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.6317 - val_loss: 0.5963\n",
      "Epoch 278/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.6659 - val_loss: 0.6385\n",
      "Epoch 279/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.6221 - val_loss: 0.6912\n",
      "Epoch 280/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.6273 - val_loss: 0.6018\n",
      "Epoch 281/400\n",
      "100/100 [==============================] - 62s 620ms/step - loss: 0.5996 - val_loss: 0.5849\n",
      "正确率: 85.00000\n",
      "Epoch 282/400\n",
      "100/100 [==============================] - 61s 615ms/step - loss: 0.6049 - val_loss: 0.5806\n",
      "Epoch 283/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.6364 - val_loss: 0.5792\n",
      "Epoch 284/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5942 - val_loss: 0.5623\n",
      "Epoch 285/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.5882 - val_loss: 0.6178\n",
      "Epoch 286/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.6380 - val_loss: 0.6074\n",
      "Epoch 287/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.6029 - val_loss: 0.5724\n",
      "Epoch 288/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5934 - val_loss: 0.5689\n",
      "Epoch 289/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.6040 - val_loss: 0.6328\n",
      "Epoch 290/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.6021 - val_loss: 0.5488\n",
      "Epoch 291/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.5907 - val_loss: 0.5420\n",
      "正确率: 88.00000\n",
      "Epoch 292/400\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.5517 - val_loss: 0.5533\n",
      "Epoch 293/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.5709 - val_loss: 0.5405\n",
      "Epoch 294/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5510 - val_loss: 0.5466\n",
      "Epoch 295/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.5353 - val_loss: 0.5645\n",
      "Epoch 296/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5690 - val_loss: 0.5795\n",
      "Epoch 297/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.6148 - val_loss: 0.6850\n",
      "Epoch 298/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.5439 - val_loss: 0.6037\n",
      "Epoch 299/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.5535 - val_loss: 0.5770\n",
      "Epoch 300/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.5723 - val_loss: 0.5097\n",
      "Epoch 301/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5668 - val_loss: 0.5773\n",
      "正确率: 83.00000\n",
      "Epoch 302/400\n",
      "100/100 [==============================] - 62s 616ms/step - loss: 0.5584 - val_loss: 0.5788\n",
      "Epoch 303/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.5858 - val_loss: 0.5327\n",
      "Epoch 304/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5990 - val_loss: 0.5370\n",
      "Epoch 305/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5486 - val_loss: 0.5163\n",
      "Epoch 306/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.5643 - val_loss: 0.5128\n",
      "Epoch 307/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.5406 - val_loss: 0.4589\n",
      "Epoch 308/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.5714 - val_loss: 0.5428\n",
      "Epoch 309/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.5439 - val_loss: 0.5580\n",
      "Epoch 310/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.5246 - val_loss: 0.5802\n",
      "Epoch 311/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.5479 - val_loss: 0.5456\n",
      "正确率: 79.00000\n",
      "Epoch 312/400\n",
      "100/100 [==============================] - 62s 615ms/step - loss: 0.5199 - val_loss: 0.5951\n",
      "Epoch 313/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5935 - val_loss: 0.4999\n",
      "Epoch 314/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.5665 - val_loss: 0.5078\n",
      "Epoch 315/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.5447 - val_loss: 0.5401\n",
      "Epoch 316/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.5321 - val_loss: 0.4944\n",
      "Epoch 317/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.5638 - val_loss: 0.4894\n",
      "Epoch 318/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.5586 - val_loss: 0.5024\n",
      "Epoch 319/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5239 - val_loss: 0.4909\n",
      "Epoch 320/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5237 - val_loss: 0.5506\n",
      "Epoch 321/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.5445 - val_loss: 0.5364\n",
      "正确率: 83.00000\n",
      "Epoch 322/400\n",
      "100/100 [==============================] - 62s 617ms/step - loss: 0.5627 - val_loss: 0.5083\n",
      "Epoch 323/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.5263 - val_loss: 0.4974\n",
      "Epoch 324/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.5277 - val_loss: 0.5783\n",
      "Epoch 325/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.5415 - val_loss: 0.5657\n",
      "Epoch 326/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.5153 - val_loss: 0.5569\n",
      "Epoch 327/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.5447 - val_loss: 0.5659\n",
      "Epoch 328/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.5257 - val_loss: 0.5627\n",
      "Epoch 329/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.5327 - val_loss: 0.5518\n",
      "Epoch 330/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5209 - val_loss: 0.5731\n",
      "Epoch 331/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5545 - val_loss: 0.5325\n",
      "正确率: 87.00000\n",
      "Epoch 332/400\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.5002 - val_loss: 0.4542\n",
      "Epoch 333/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.5346 - val_loss: 0.5049\n",
      "Epoch 334/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.5036 - val_loss: 0.4692\n",
      "Epoch 335/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.5292 - val_loss: 0.5029\n",
      "Epoch 336/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.5149 - val_loss: 0.4681\n",
      "Epoch 337/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.5181 - val_loss: 0.4616\n",
      "Epoch 338/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4963 - val_loss: 0.5119\n",
      "Epoch 339/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5315 - val_loss: 0.4493\n",
      "Epoch 340/400\n",
      "100/100 [==============================] - 63s 625ms/step - loss: 0.5217 - val_loss: 0.5153\n",
      "Epoch 341/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.5000 - val_loss: 0.5169\n",
      "正确率: 82.00000\n",
      "Epoch 342/400\n",
      "100/100 [==============================] - 62s 618ms/step - loss: 0.5371 - val_loss: 0.4707\n",
      "Epoch 343/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.5402 - val_loss: 0.5620\n",
      "Epoch 344/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.4982 - val_loss: 0.4752\n",
      "Epoch 345/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.5131 - val_loss: 0.5174\n",
      "Epoch 346/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.5350 - val_loss: 0.4822\n",
      "Epoch 347/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.5057 - val_loss: 0.5066\n",
      "Epoch 348/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.4958 - val_loss: 0.4552\n",
      "Epoch 349/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4897 - val_loss: 0.5233\n",
      "Epoch 350/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4990 - val_loss: 0.4584\n",
      "Epoch 351/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.4501 - val_loss: 0.5083\n",
      "正确率: 85.00000\n",
      "Epoch 352/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.4993 - val_loss: 0.4880\n",
      "Epoch 353/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.6297 - val_loss: 0.5465\n",
      "Epoch 354/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.4917 - val_loss: 0.4717\n",
      "Epoch 355/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.4980 - val_loss: 0.4839\n",
      "Epoch 356/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4811 - val_loss: 0.4621\n",
      "Epoch 357/400\n",
      "100/100 [==============================] - 62s 623ms/step - loss: 0.4469 - val_loss: 0.4893\n",
      "Epoch 358/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4809 - val_loss: 0.4870\n",
      "Epoch 359/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4612 - val_loss: 0.4279\n",
      "Epoch 360/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.4834 - val_loss: 0.4046\n",
      "Epoch 361/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4577 - val_loss: 0.4810\n",
      "正确率: 87.00000\n",
      "Epoch 362/400\n",
      "100/100 [==============================] - 62s 619ms/step - loss: 0.4585 - val_loss: 0.5411\n",
      "Epoch 363/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.4887 - val_loss: 0.5041\n",
      "Epoch 364/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.4593 - val_loss: 0.4137\n",
      "Epoch 365/400\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.4970 - val_loss: 0.4515\n",
      "Epoch 366/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4753 - val_loss: 0.4521\n",
      "Epoch 367/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4729 - val_loss: 0.4565\n",
      "Epoch 368/400\n",
      "100/100 [==============================] - 62s 622ms/step - loss: 0.4768 - val_loss: 0.4386\n",
      "Epoch 369/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.4610 - val_loss: 0.4876\n",
      "Epoch 370/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.4764 - val_loss: 0.5137\n",
      "Epoch 371/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4584 - val_loss: 0.4143\n",
      "正确率: 92.00000\n",
      "Epoch 372/400\n",
      "100/100 [==============================] - 62s 620ms/step - loss: 0.4902 - val_loss: 0.4121\n",
      "Epoch 373/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.4542 - val_loss: 0.4655\n",
      "Epoch 374/400\n",
      "100/100 [==============================] - 63s 626ms/step - loss: 0.4887 - val_loss: 0.5387\n",
      "Epoch 375/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.4777 - val_loss: 0.4648\n",
      "Epoch 376/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4769 - val_loss: 0.4408\n",
      "Epoch 377/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.4543 - val_loss: 0.5170\n",
      "Epoch 378/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.4836 - val_loss: 0.4287\n",
      "Epoch 379/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 0.4562 - val_loss: 0.4837\n",
      "Epoch 380/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.4618 - val_loss: 0.4521\n",
      "Epoch 381/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 63s 629ms/step - loss: 0.4873 - val_loss: 0.4389\n",
      "正确率: 87.00000\n",
      "Epoch 382/400\n",
      "100/100 [==============================] - 62s 620ms/step - loss: 0.4750 - val_loss: 0.4856\n",
      "Epoch 383/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.4595 - val_loss: 0.4734\n",
      "Epoch 384/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.4890 - val_loss: 0.4139\n",
      "Epoch 385/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.4215 - val_loss: 0.3577\n",
      "Epoch 386/400\n",
      "100/100 [==============================] - 63s 627ms/step - loss: 0.4357 - val_loss: 0.4341\n",
      "Epoch 387/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.4804 - val_loss: 0.5241\n",
      "Epoch 388/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.4719 - val_loss: 0.3929\n",
      "Epoch 389/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 0.4958 - val_loss: 0.4135\n",
      "Epoch 390/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.4681 - val_loss: 0.3722\n",
      "Epoch 391/400\n",
      "100/100 [==============================] - 62s 625ms/step - loss: 0.4346 - val_loss: 0.4373\n",
      "正确率: 88.00000\n",
      "Epoch 392/400\n",
      "100/100 [==============================] - 62s 621ms/step - loss: 0.4758 - val_loss: 0.4483\n",
      "Epoch 393/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 0.4653 - val_loss: 0.3593\n",
      "Epoch 394/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 0.4363 - val_loss: 0.4158\n",
      "Epoch 395/400\n",
      "100/100 [==============================] - 63s 629ms/step - loss: 0.4445 - val_loss: 0.3962\n",
      "Epoch 396/400\n",
      "100/100 [==============================] - 63s 628ms/step - loss: 0.4354 - val_loss: 0.4319\n",
      "Epoch 397/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.4737 - val_loss: 0.4348\n",
      "Epoch 398/400\n",
      "100/100 [==============================] - 63s 630ms/step - loss: 0.4267 - val_loss: 0.4548\n",
      "Epoch 399/400\n",
      "100/100 [==============================] - 63s 631ms/step - loss: 0.4542 - val_loss: 0.3794\n",
      "Epoch 400/400\n",
      "100/100 [==============================] - 63s 632ms/step - loss: 0.4460 - val_loss: 0.4247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ce86182748>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "# captures output of softmax so we can decode the output during visualization\n",
    "test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "viz_cb = VizCallback(datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S'), test_func, img_gen.get_next_val())\n",
    "# evaluate_gen = TextImageGenerator(train_path, validate_path, img_w, img_h, channel, downsample_factor)\n",
    "# evaluator = Evaluator(test_func, evaluate_gen)\n",
    "\n",
    "model.fit_generator(generator=img_gen.get_next_train(100),\n",
    "                    steps_per_epoch=100,\n",
    "                    epochs=400,\n",
    "                    validation_data=img_gen.get_next_val(1000),\n",
    "                    validation_steps=5,\n",
    "                    callbacks=[viz_cb],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "generator = img_gen.get_next_val(2)\n",
    "_x_input, _  = next(generator)\n",
    "_X_test = _x_input['the_input']\n",
    "_y_test = _x_input['the_labels']\n",
    "\n",
    "img = _X_test[0]\n",
    "print(img.shape)\n",
    "print(np.einsum('hwc->whc', img).shape)\n",
    "print(img[:, :, 0].T.shape)\n",
    "print(np.max(img.flatten()))\n",
    "print(np.min(img.flatten()))\n",
    "print(_X_test[0].flatten().shape)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img[:, :, 0].T)\n",
    "plt.subplot(1, 2, 2)\n",
    "img = np.einsum('hwc->whc', img)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# for i in range(_y_pred.shape[0]):\n",
    "#     _y_pred = base_model.predict(np.expand_dims(_X_test[i], axis=0))[:, 2:, :]\n",
    "#     print(_y_pred.shape)\n",
    "#     for i in range(_y_pred.shape[0]):\n",
    "#         __X_test = _X_test[i]\n",
    "#         __y_test = _y_test[i]\n",
    "#         __y_pred = _y_pred[i]\n",
    "#         __y_pred = np.expand_dims(__y_pred, axis=0)\n",
    "#         shape = __y_pred.shape\n",
    "#         ctc_decode = K.ctc_decode(__y_pred, \n",
    "#                                   input_length=np.ones(shape[0])*shape[1])[0][0]\n",
    "#         out = K.get_value(ctc_decode)[0]\n",
    "#         print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n",
    "from IPython.display import Image\n",
    "Image(filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./weights/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_path = 'E:\\\\traindata\\\\captcha_create\\\\train'\n",
    "validate_path = 'E:\\\\traindata\\\\captcha_create\\\\test'\n",
    "test_img = os.path.join(train_path, '00ARLO.jpg')\n",
    "\n",
    "img_w = 200\n",
    "img_h = 60\n",
    "channel = 3\n",
    "downsample_factor = 4\n",
    "gen = TextImageGenerator(train_path, validate_path, img_w, img_h, channel, downsample_factor)\n",
    "for i in range(40):\n",
    "    next(gen.get_next_train(500))\n",
    "\n",
    "imgs = next(gen.get_next_train(2))\n",
    "_x, _ctc = imgs[0], imgs[1]\n",
    "\n",
    "_the_input = _x['the_input']\n",
    "_the_labels = _x['the_labels']\n",
    "_input_length = _x['input_length']\n",
    "_label_length = _x['label_length']\n",
    "print(_ctc)\n",
    "num = _the_input.shape[0]\n",
    "\n",
    "for i in range(num):\n",
    "    img = _the_input[i]\n",
    "    print(img.shape)\n",
    "    plt.subplot(1, num, i + 1)\n",
    "    plt.xlabel('label: %s' % _the_labels[i])\n",
    "    plt.imshow(img[:, :, 0], cmap='Greys_r')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('E:\\\\Workplace\\\\bdzh\\\\MachineLearning\\\\SmallCaptcha\\\\image_ocr\\\\2019_05_23_23_32_26\\\\weights400.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
