{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import codecs\n",
    "import re\n",
    "import datetime\n",
    "# import cairocffi as cairo\n",
    "# import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "# import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks\n",
    "import pathlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TextImageGenerator(keras.callbacks.Callback):\n",
    "    # 所有可能字符\n",
    "    LABELS = '0123456789abcdefghijklmnopqrstuvwxyz '\n",
    "    \n",
    "    def __init__(self, train_path, validate_path, img_w, img_h, channel, downsample_factor, absolute_max_string_len=6):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            train_path: 训练数据路径\n",
    "            validate_path: 验证图片路径\n",
    "            img_w:\n",
    "            img_h:\n",
    "            downsample_factor: TODO 未知\n",
    "            absolute_max_string_len: 最大字符串长度\n",
    "        \"\"\"\n",
    "        self.img_w = img_w\n",
    "        self.img_h = img_h\n",
    "        self.channel = channel\n",
    "        self.train_path = train_path\n",
    "        self.validate_path = validate_path\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.blank_label = self.get_output_size() - 1\n",
    "        self.absolute_max_string_len = absolute_max_string_len\n",
    "        # 数据\n",
    "        self.train_imgs = self.get_all_imgs(self.train_path)\n",
    "        self.validate_imgs = self.get_all_imgs(self.validate_path)\n",
    "        self.cur_idx = 0\n",
    "        \n",
    "        np.random.shuffle(self.train_imgs)\n",
    "        np.random.shuffle(self.validate_imgs)\n",
    "    \n",
    "    def get_all_imgs(self, path):\n",
    "#         p = pathlib.Path(path)\n",
    "        # jpg or png\n",
    "#         return list([str(i) for i in p.glob('*.jpg')])\n",
    "        return [os.path.join(path, i) for i in os.listdir(path)]\n",
    "    \n",
    "    def get_output_size(self):\n",
    "        return len(self.LABELS) + 1\n",
    "    \n",
    "    def char2idx(self, char):\n",
    "        idx = self.LABELS.find(char)\n",
    "        return idx if idx != -1 else self.blank_label\n",
    "    \n",
    "    @staticmethod\n",
    "    def labels_to_text(labels):\n",
    "        ret = []\n",
    "        for c in labels:\n",
    "            if c == len(TextImageGenerator.LABELS):  # CTC Blank\n",
    "                ret.append(\"\")\n",
    "            else:\n",
    "                ret.append(TextImageGenerator.LABELS[c])\n",
    "        return \"\".join(ret)\n",
    "    \n",
    "    def path2matrix(self, path):\n",
    "        \"\"\"\n",
    "        input shape: (batch_size, w, h, channel)\n",
    "        \"\"\"\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_transpose = np.einsum('hw->wh', img)\n",
    "        img_transpose = np.expand_dims(img_transpose, axis=-1)\n",
    "        return img_transpose\n",
    "\n",
    "    def get_next_batch(self, paths, batch_size=32):\n",
    "        def get_label(img_path):\n",
    "            \"\"\"\n",
    "            获取验证码对应的字符串\n",
    "            \"\"\"\n",
    "            return os.path.basename(img_path).split('.')[0].lower()\n",
    "        i = 0\n",
    "        X_data = np.zeros((batch_size, self.img_w, self.img_h, self.channel))\n",
    "        labels = np.zeros((batch_size, self.absolute_max_string_len))\n",
    "        input_length = np.zeros([batch_size, 1])\n",
    "        label_length = np.zeros([batch_size, 1])\n",
    "        source_str = []\n",
    "        while i < batch_size:\n",
    "            if self.cur_idx >= len(paths):\n",
    "                # 归零，洗牌\n",
    "                self.cur_idx = 0\n",
    "                np.random.shuffle(paths)\n",
    "            img_path = paths[self.cur_idx]\n",
    "            label_text = get_label(img_path)\n",
    "            X_data[i, :] = self.path2matrix(img_path)\n",
    "            input_length[i] = self.img_w // self.downsample_factor - 2\n",
    "            label_length[i] = len(label_text)\n",
    "            labels[i] = [self.char2idx(char) for char in label_text]\n",
    "            source_str.append(label_text)\n",
    "            \n",
    "            self.cur_idx += 1\n",
    "            i += 1\n",
    "            \n",
    "        inputs = {\n",
    "              'the_input': X_data,\n",
    "              'the_labels': labels,\n",
    "              'input_length': input_length,\n",
    "              'label_length': label_length,\n",
    "              'source_str': source_str  # used for visualization only\n",
    "        }\n",
    "        outputs = {'ctc': np.zeros([batch_size])}\n",
    "        return (inputs, outputs)\n",
    "            \n",
    "    def get_next_train(self, batch_size=32):\n",
    "        while True:\n",
    "            yield self.get_next_batch(self.train_imgs, batch_size)\n",
    "    \n",
    "    def get_next_val(self, batch_size=32):\n",
    "        while True:\n",
    "            yield self.get_next_batch(self.validate_imgs, batch_size)\n",
    "        \n",
    "\n",
    "\n",
    "train_path = 'E:\\\\traindata\\\\captcha_create\\\\train'\n",
    "validate_path = 'E:\\\\traindata\\\\captcha_create\\\\test'\n",
    "test_img = os.path.join(train_path, '00ARLO.jpg')\n",
    "\n",
    "img_w = 200\n",
    "img_h = 60\n",
    "channel = 1\n",
    "downsample_factor = 4\n",
    "img_gen = TextImageGenerator(train_path, validate_path, img_w, img_h, channel, downsample_factor)\n",
    "# ret_input, ret_output = next(img_gen.get_next_train(3))\n",
    "# ret_input, ret_output = next(img_gen.get_next_train(3))\n",
    "# print(ret_input['the_input'].shape)\n",
    "# print(ret_input['the_labels'])\n",
    "# print(ret_input['input_length'])\n",
    "# print(ret_input['label_length'])\n",
    "# print(ret_input['source_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 200, 60, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 200, 60, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 100, 30, 16)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 100, 30, 16)  2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 50, 15, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 240)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 50, 32)       7712        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 50, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 50, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 50, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 50, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 50, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 50, 38)       38950       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 50, 38)       0           dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,872,182\n",
      "Trainable params: 4,872,182\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\ipykernel_launcher.py:59: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"th..., outputs=Tensor(\"so...)`\n"
     ]
    }
   ],
   "source": [
    "# img_w = 200\n",
    "# # Input Parameters\n",
    "# img_h = 60\n",
    "# channel = 1\n",
    "# Network parameters\n",
    "conv_filters = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "rnn_size = 512\n",
    "minibatch_size = 32\n",
    "OUTPUT_DIR = 'E:\\\\Workplace\\\\bdzh\\\\MachineLearning\\\\SmallCaptcha\\\\image_ocr'\n",
    "\n",
    "\n",
    "# the actual loss calc occurs here despite it not being\n",
    "# an internal Keras loss function\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (channel, img_w, img_h)\n",
    "else:\n",
    "    input_shape = (img_w, img_h, channel)\n",
    "\n",
    "act = 'relu'\n",
    "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv1')(input_data)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',\n",
    "               activation=act, kernel_initializer='he_normal',\n",
    "               name='conv2')(inner)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "# cuts down input size going into RNN:\n",
    "inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "# Two layers of bidirectional GRUs\n",
    "# GRU seems to work as well, if not better than LSTM:\n",
    "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "gru1_merged = add([gru_1, gru_1b])\n",
    "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "# transforms RNN output to character activations:\n",
    "inner = Dense(img_gen.get_output_size(), kernel_initializer='he_normal',\n",
    "              name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    "base_model = Model(input=input_data, output=y_pred)\n",
    "base_model.summary()\n",
    "\n",
    "labels = Input(name='the_labels', shape=[img_gen.absolute_max_string_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "# Keras doesn't currently support loss funcs with extra parameters\n",
    "# so CTC loss is implemented in a lambda layer\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "# clipnorm seems to speeds up convergence\n",
    "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "\n",
    "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VizCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, run_name, test_func, text_img_gen, num_display_words=6):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            OUTPUT_DIR, run_name)\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            num_proc = min(word_batch['the_input'].shape[0], num_left)\n",
    "            decoded_res = decode_batch(self.test_func, word_batch['the_input'][0:num_proc])\n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j], word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(word_batch['source_str'][j])\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance: %.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "#         self.show_edit_distance(256)\n",
    "        word_batch = next(self.text_img_gen)[0]\n",
    "        res = decode_batch(self.test_func, word_batch['the_input'][0:self.num_display_words])\n",
    "        if word_batch['the_input'][0].shape[0] < 256:\n",
    "            cols = 2\n",
    "        else:\n",
    "            cols = 1\n",
    "        for i in range(self.num_display_words):\n",
    "            plt.subplot(self.num_display_words // cols, cols, i + 1)\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                the_input = word_batch['the_input'][i, 0, :, :]\n",
    "            else:\n",
    "                the_input = word_batch['the_input'][i, :, :, 0]\n",
    "            plt.imshow(the_input.T, cmap='Greys_r')\n",
    "            plt.xlabel('T = \\'%s\\' Decoed = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "#             print(('Truth = \\'%s\\'\\nDecoded = \\'%s\\'' % (word_batch['source_str'], res)))\n",
    "#         plt.show()\n",
    "#         fig = pylab.gcf()\n",
    "#         fig = plt.figure(figsize=(30, 30))\n",
    "#         fig.set_size_inches(10, 13)\n",
    "        plt.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n",
    "        plt.close()\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = TextImageGenerator.labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, batch_num=50):\n",
    "    batch_acc = 0\n",
    "    generator = img_gen.get_next_val(batch_num)\n",
    "    x_input, _  = next(generator)\n",
    "    X_test = x_input['the_input']\n",
    "    y_test = x_input['the_labels']\n",
    "    y_pred = base_model.predict(X_test)[:, 2:, :]\n",
    "    \n",
    "    for i in range(batch_num):\n",
    "#         [X_test, y_test, _, _]\n",
    "        _X_test = X_test[i]\n",
    "        _y_test = y_test[i]\n",
    "        _y_pred = y_pred[i]\n",
    "        _y_pred = np.expand_dims(_y_pred, axis=0)\n",
    "        shape = _y_pred.shape\n",
    "        ctc_decode = K.ctc_decode(_y_pred, \n",
    "                                  input_length=np.ones(shape[0])*shape[1])[0][0]\n",
    "        out = K.get_value(ctc_decode)[0]\n",
    "        if np.all(y_test == out):\n",
    "            batch_acc += 1\n",
    "            \n",
    "        if i < 6:\n",
    "            print('origin: %s, decoded: %s' % (_y_test, out))\n",
    "    return batch_acc / batch_num\n",
    "\n",
    "class Evaluate(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.accs = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        acc = evaluate(base_model)*100\n",
    "        self.accs.append(acc)\n",
    "        print()\n",
    "        print('acc: %f%%'%acc)\n",
    "evaluator = Evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 134s 1s/step - loss: 36.0208 - val_loss: 27.3773\n",
      "WARNING:tensorflow:From E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4303: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "origin: [16.  7.  2. 34.  1. 28.], decoded: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: [10. 29.  1. 34. 23.  2.], decoded: []\n",
      "origin: [21. 19. 13. 17. 24.  0.], decoded: []\n",
      "origin: [21. 34. 16. 31. 16. 29.], decoded: []\n",
      "origin: [ 4. 27. 10.  7. 24. 19.], decoded: []\n",
      "origin: [14. 24.  0. 11. 15. 28.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 33s 271ms/step - loss: 24.8175 - val_loss: 25.2930\n",
      "origin: [25.  1.  7. 17.  9. 28.], decoded: [4]\n",
      "origin: [19. 13.  9. 33. 12. 16.], decoded: [4]\n",
      "origin: [ 9. 29. 30.  0. 24. 33.], decoded: [4]\n",
      "origin: [16. 23. 19. 32. 19.  6.], decoded: [4]\n",
      "origin: [24. 29. 10.  0. 21. 35.], decoded: [4]\n",
      "origin: [19. 16. 31.  4. 29. 24.], decoded: [4]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 24.2587 - val_loss: 24.5237\n",
      "origin: [ 1.  8. 11.  6. 16.  7.], decoded: [8]\n",
      "origin: [ 1. 25. 34. 13. 18.  1.], decoded: [8]\n",
      "origin: [ 9. 23. 10.  4. 24.  3.], decoded: [8]\n",
      "origin: [31. 28.  3. 33. 20.  4.], decoded: [8]\n",
      "origin: [10.  2. 24.  5. 12. 22.], decoded: [8]\n",
      "origin: [ 1. 18. 27.  5. 34. 28.], decoded: [8]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 24.1070 - val_loss: 23.9418\n",
      "origin: [17. 33.  3. 30. 28. 19.], decoded: [5]\n",
      "origin: [32. 23.  1. 31. 17. 35.], decoded: [5]\n",
      "origin: [32. 20. 34. 23.  8.  6.], decoded: [5]\n",
      "origin: [34. 33.  4.  9. 21.  3.], decoded: [5]\n",
      "origin: [35. 17.  4. 27. 24. 13.], decoded: [5]\n",
      "origin: [20. 32. 25. 11. 23. 23.], decoded: [5]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 23.9089 - val_loss: 23.9317\n",
      "origin: [27. 18. 10.  0. 34. 27.], decoded: [ 9 24]\n",
      "origin: [11. 14. 33.  6. 16. 15.], decoded: [ 9 24]\n",
      "origin: [24. 23. 21.  1. 35. 30.], decoded: [ 9 24]\n",
      "origin: [ 5. 16. 10.  4. 30. 20.], decoded: [ 9 24]\n",
      "origin: [10. 35.  0.  8. 12.  6.], decoded: [ 9 24]\n",
      "origin: [ 2. 24. 20.  3. 19.  6.], decoded: [ 9 24]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 33s 271ms/step - loss: 23.3620 - val_loss: 22.9604\n",
      "origin: [14. 31. 22. 28.  2.  5.], decoded: [3 9]\n",
      "origin: [16. 33. 27.  7. 32.  6.], decoded: [3 9]\n",
      "origin: [24.  9. 20. 24. 31. 12.], decoded: [3 9]\n",
      "origin: [29. 31. 25.  0. 16. 15.], decoded: [3 9]\n",
      "origin: [30. 29. 18. 10.  7. 19.], decoded: [3 9]\n",
      "origin: [32. 28. 34. 24. 25. 12.], decoded: [3 9]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 22.9200 - val_loss: 22.5853\n",
      "origin: [23. 34. 16.  6. 34. 32.], decoded: [21 29 21]\n",
      "origin: [ 6.  3. 30. 31. 35. 22.], decoded: [21 29 21]\n",
      "origin: [13. 15. 25. 30.  1.  8.], decoded: [21 29 21]\n",
      "origin: [ 7. 30. 17. 28. 15. 20.], decoded: [21 29 21]\n",
      "origin: [24. 17. 35. 30. 30. 35.], decoded: [21 29 21]\n",
      "origin: [32. 24. 12. 32. 13.  3.], decoded: [21 29 21]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 32s 270ms/step - loss: 22.9444 - val_loss: 22.7523\n",
      "origin: [10. 34. 33. 24. 34. 31.], decoded: []\n",
      "origin: [23. 32. 18. 10. 34. 25.], decoded: []\n",
      "origin: [30.  2.  7. 18. 10. 10.], decoded: []\n",
      "origin: [25. 16. 14. 29. 16. 14.], decoded: []\n",
      "origin: [17.  5. 21. 21.  2. 28.], decoded: []\n",
      "origin: [23. 12. 22. 10. 35. 19.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 22.6956 - val_loss: 23.2194\n",
      "origin: [33. 14. 25. 17. 17. 35.], decoded: [4 3 9]\n",
      "origin: [10. 21.  2. 32.  7. 14.], decoded: [4 3 9]\n",
      "origin: [17. 11.  7.  9.  3. 22.], decoded: [4 3 9]\n",
      "origin: [15. 16. 33. 10.  3. 15.], decoded: [4 3 9]\n",
      "origin: [27. 31. 30.  7.  5. 16.], decoded: [4 3 9]\n",
      "origin: [10. 29. 28. 32. 12.  3.], decoded: [4 3 9]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 33s 275ms/step - loss: 24.2067 - val_loss: 23.1225\n",
      "origin: [ 3. 32. 24. 25. 22.  4.], decoded: [8 8]\n",
      "origin: [16. 24.  3. 18. 14. 20.], decoded: [8 8]\n",
      "origin: [19.  4.  0. 18.  1. 23.], decoded: [8 8]\n",
      "origin: [24. 35. 30. 11. 16. 11.], decoded: [8 8]\n",
      "origin: [ 1.  2.  1. 32. 16. 21.], decoded: [8 8]\n",
      "origin: [ 0. 20. 25. 20.  7. 23.], decoded: [8 8]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 33s 276ms/step - loss: 23.0499 - val_loss: 22.7107\n",
      "origin: [24.  8. 33. 10. 13.  5.], decoded: []\n",
      "origin: [ 8. 32. 28. 30.  3.  9.], decoded: []\n",
      "origin: [33. 11. 21. 32. 20.  3.], decoded: []\n",
      "origin: [24. 35. 11.  2. 10.  6.], decoded: []\n",
      "origin: [16. 11. 32.  9. 10. 34.], decoded: []\n",
      "origin: [ 3. 10. 28.  1. 24.  4.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 34s 282ms/step - loss: 22.7170 - val_loss: 22.7918\n",
      "origin: [23. 17. 21. 30. 11. 24.], decoded: [8]\n",
      "origin: [24. 19.  0. 12.  2. 19.], decoded: [8]\n",
      "origin: [23.  9.  9. 34. 33.  2.], decoded: [8]\n",
      "origin: [20. 10. 23. 12. 34. 11.], decoded: [8]\n",
      "origin: [ 6. 24. 35.  2. 24. 17.], decoded: [8]\n",
      "origin: [27. 31. 35.  7. 31. 17.], decoded: [8]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 22.5328 - val_loss: 22.7244\n",
      "origin: [ 8. 15. 27. 14. 14. 23.], decoded: [8]\n",
      "origin: [32. 28. 34. 24. 25. 12.], decoded: [8]\n",
      "origin: [12. 28. 24. 24. 18. 28.], decoded: [8]\n",
      "origin: [15.  6. 28. 16.  3. 19.], decoded: [8]\n",
      "origin: [25.  2. 17. 25. 22. 10.], decoded: [8]\n",
      "origin: [17. 19. 17. 12. 13.  9.], decoded: [8]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 32s 267ms/step - loss: 22.5026 - val_loss: 22.5131\n",
      "origin: [19. 31. 19. 34. 28. 23.], decoded: [8 8]\n",
      "origin: [16.  9. 27.  2.  2.  8.], decoded: [8 8]\n",
      "origin: [ 3. 20. 35. 22. 29. 24.], decoded: [8 8]\n",
      "origin: [25. 13. 22.  5.  0. 16.], decoded: [8 8]\n",
      "origin: [15.  4. 22. 19.  0. 20.], decoded: [8 8]\n",
      "origin: [ 4. 32. 28. 12.  5.  3.], decoded: [8 8]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 32s 268ms/step - loss: 22.4823 - val_loss: 22.5015\n",
      "origin: [15. 29.  4. 22.  1.  9.], decoded: [8 8]\n",
      "origin: [20.  7. 34. 19.  0. 14.], decoded: [8 8]\n",
      "origin: [13. 25. 20.  0. 23. 16.], decoded: [8 8]\n",
      "origin: [33. 35.  8. 34. 25. 33.], decoded: [8 8]\n",
      "origin: [16. 12.  7. 19.  0. 25.], decoded: [8 8]\n",
      "origin: [29. 20. 32. 15.  2. 31.], decoded: [8 8]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 32s 268ms/step - loss: 22.4809 - val_loss: 22.4799\n",
      "origin: [31. 29. 14. 12. 19. 31.], decoded: [8 8]\n",
      "origin: [29. 24.  1. 12.  6.  8.], decoded: [8 8]\n",
      "origin: [27. 18. 10.  0. 34. 27.], decoded: [8 8]\n",
      "origin: [12. 21. 23. 29. 31. 25.], decoded: [8 8]\n",
      "origin: [ 2. 30. 24. 21. 28.  8.], decoded: [8 8]\n",
      "origin: [19. 29. 12.  8. 24. 31.], decoded: [8 8]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 36s 301ms/step - loss: 22.5065 - val_loss: 22.4727\n",
      "origin: [25. 27. 28. 12.  8. 28.], decoded: [8 5 8]\n",
      "origin: [22.  0.  2.  6. 15.  6.], decoded: [8 5 8]\n",
      "origin: [27. 12. 34. 11. 24.  2.], decoded: [8 5 8]\n",
      "origin: [25. 33. 13.  2.  2. 33.], decoded: [8 5 8]\n",
      "origin: [ 7. 32.  2.  5. 19. 15.], decoded: [8 5 8]\n",
      "origin: [33. 22. 24. 23.  0. 28.], decoded: [8 5 8]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 32s 270ms/step - loss: 22.4783 - val_loss: 22.4662\n",
      "origin: [31. 14. 15. 10.  6.  9.], decoded: [24 24  4]\n",
      "origin: [12. 13. 29. 25.  3. 33.], decoded: [24 24  4]\n",
      "origin: [27. 16. 18. 29. 11.  8.], decoded: [24 24  4]\n",
      "origin: [ 3.  3. 22.  8.  4.  3.], decoded: [24 24  4]\n",
      "origin: [28. 35. 30. 33. 23. 35.], decoded: [24 24  4]\n",
      "origin: [16. 14. 17. 10. 10. 17.], decoded: [24 24  4]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 33s 278ms/step - loss: 22.5566 - val_loss: 22.4000\n",
      "origin: [20. 31.  5.  6. 30. 13.], decoded: [24]\n",
      "origin: [ 0. 11. 19. 29. 28. 10.], decoded: [24]\n",
      "origin: [24. 11. 28. 27. 20. 17.], decoded: [24]\n",
      "origin: [ 9. 19. 10. 24. 20. 30.], decoded: [24]\n",
      "origin: [ 1. 32. 24.  3.  0.  8.], decoded: [24]\n",
      "origin: [10. 16. 19.  2. 33. 13.], decoded: [24]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 22.4827 - val_loss: 22.4201\n",
      "origin: [25.  4.  4. 17.  2. 18.], decoded: [16  4 34]\n",
      "origin: [24.  3. 14. 32.  7. 24.], decoded: [16  4 34]\n",
      "origin: [ 5.  7. 11.  3.  0. 17.], decoded: [16  4 34]\n",
      "origin: [ 4. 27. 21.  9. 10. 32.], decoded: [16  4 34]\n",
      "origin: [35. 32. 16. 24.  7. 25.], decoded: [16  4 34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: [10.  3. 22. 19. 21. 28.], decoded: [16  4 34]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 22.4487 - val_loss: 22.4013\n",
      "origin: [ 6. 29.  3.  5.  2. 22.], decoded: [ 7 24 24]\n",
      "origin: [22. 22. 10. 33. 30. 16.], decoded: [ 7 24 24]\n",
      "origin: [ 2. 24. 24. 30. 10.  0.], decoded: [ 7 24 24]\n",
      "origin: [35.  1. 30.  9. 33. 13.], decoded: [ 7 24 24]\n",
      "origin: [33.  4. 22. 10. 20.  0.], decoded: [ 7 24 24]\n",
      "origin: [ 6. 16.  4. 11. 20. 18.], decoded: [ 7 24 24]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 32s 270ms/step - loss: 22.7858 - val_loss: 22.5269\n",
      "origin: [17. 14. 35. 11. 16. 19.], decoded: [ 7  3 24 24]\n",
      "origin: [ 3. 28. 24. 35. 33.  7.], decoded: [ 7  3 24 24]\n",
      "origin: [20.  2.  2. 21. 30. 10.], decoded: [ 7  3 24 24]\n",
      "origin: [18.  0. 17.  3. 35. 23.], decoded: [ 7  3 24 24]\n",
      "origin: [22. 27. 28.  1. 15. 11.], decoded: [ 7  3 24 24]\n",
      "origin: [29. 21. 31. 18. 28. 25.], decoded: [ 7  3 24 24]\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 25.4139 - val_loss: 24.8222\n",
      "origin: [15. 23. 11.  5. 24. 20.], decoded: []\n",
      "origin: [33.  6.  0. 35.  1.  4.], decoded: []\n",
      "origin: [16. 13. 19. 10. 10. 10.], decoded: []\n",
      "origin: [10.  1. 35. 35. 20.  2.], decoded: []\n",
      "origin: [14.  6.  2. 15.  5.  8.], decoded: []\n",
      "origin: [14. 20. 34. 33. 20. 24.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 33s 276ms/step - loss: 24.5086 - val_loss: 24.6496\n",
      "origin: [ 3. 34. 30.  7. 22. 10.], decoded: []\n",
      "origin: [27. 32. 28. 35.  6. 29.], decoded: []\n",
      "origin: [ 7.  3. 31.  3. 23. 24.], decoded: []\n",
      "origin: [23.  2.  8. 34. 23.  6.], decoded: []\n",
      "origin: [25.  0. 14.  4.  8.  1.], decoded: []\n",
      "origin: [31. 14. 32. 33. 24.  5.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 32s 269ms/step - loss: 24.3475 - val_loss: 24.4129\n",
      "origin: [24.  8. 32.  9. 32.  5.], decoded: []\n",
      "origin: [35. 10.  8. 19.  6. 24.], decoded: []\n",
      "origin: [34.  4.  5. 10.  6.  5.], decoded: []\n",
      "origin: [34. 24.  9. 33. 33.  8.], decoded: []\n",
      "origin: [ 6. 33. 25. 23. 10. 24.], decoded: []\n",
      "origin: [20. 17.  6. 28. 29. 16.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 26.5692 - val_loss: 25.0783\n",
      "origin: [27.  1.  1. 23.  9. 30.], decoded: []\n",
      "origin: [10. 32. 21. 22. 33. 16.], decoded: []\n",
      "origin: [35. 21. 20.  8.  2. 22.], decoded: []\n",
      "origin: [28. 17.  2.  5.  3. 11.], decoded: []\n",
      "origin: [ 2. 23. 34. 11. 31. 11.], decoded: []\n",
      "origin: [10. 21. 32. 24.  8. 10.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 24.4155 - val_loss: 24.6205\n",
      "origin: [ 7. 31.  5.  4. 33. 24.], decoded: []\n",
      "origin: [27.  2. 33.  4. 25. 28.], decoded: []\n",
      "origin: [ 5. 24. 18. 24.  4. 29.], decoded: []\n",
      "origin: [11. 15. 12. 33.  6.  2.], decoded: []\n",
      "origin: [24. 22. 33. 10.  0. 12.], decoded: []\n",
      "origin: [35. 21. 20.  8.  2. 22.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 32s 271ms/step - loss: 24.3829 - val_loss: 24.5924\n",
      "origin: [18. 22.  7.  2.  0. 14.], decoded: []\n",
      "origin: [25. 24. 34. 11.  6. 24.], decoded: []\n",
      "origin: [10. 14. 10. 21. 24.  9.], decoded: []\n",
      "origin: [20. 24. 10. 30. 24.  9.], decoded: []\n",
      "origin: [13. 25. 17. 13. 23.  3.], decoded: []\n",
      "origin: [28. 16. 27. 24. 17. 18.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 34s 284ms/step - loss: 24.3422 - val_loss: 24.5829\n",
      "origin: [16.  7.  7. 15.  1.  5.], decoded: []\n",
      "origin: [ 6. 15.  3.  9. 29.  6.], decoded: []\n",
      "origin: [ 5.  1. 25. 16. 11.  8.], decoded: []\n",
      "origin: [ 1. 32. 10.  9.  1.  0.], decoded: []\n",
      "origin: [30.  5.  2.  9. 23. 25.], decoded: []\n",
      "origin: [35. 15.  7. 11. 10. 33.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 24.3103 - val_loss: 24.5289\n",
      "origin: [21. 24. 22. 19. 28. 18.], decoded: []\n",
      "origin: [12. 15. 10. 17. 19. 21.], decoded: []\n",
      "origin: [23. 27.  2. 35. 33.  1.], decoded: []\n",
      "origin: [32. 29. 17. 33. 25. 11.], decoded: []\n",
      "origin: [33. 25. 18. 34. 35. 21.], decoded: []\n",
      "origin: [ 5. 35.  5. 32. 10. 13.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 34s 280ms/step - loss: 24.2989 - val_loss: 24.5156\n",
      "origin: [16. 22.  5.  8. 14. 29.], decoded: []\n",
      "origin: [19.  7.  1. 20. 20. 20.], decoded: []\n",
      "origin: [31. 11. 13.  2. 12. 27.], decoded: []\n",
      "origin: [ 2. 27.  8. 15. 31. 33.], decoded: []\n",
      "origin: [23.  1. 35. 21. 19. 34.], decoded: []\n",
      "origin: [27. 21.  7. 13. 31. 30.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 24.2976 - val_loss: 24.5179\n",
      "origin: [ 2. 32.  9. 27. 11. 24.], decoded: []\n",
      "origin: [15. 19. 23.  1.  0. 16.], decoded: []\n",
      "origin: [ 2. 21.  9. 13. 15. 17.], decoded: []\n",
      "origin: [28. 34. 29. 24. 32. 14.], decoded: []\n",
      "origin: [24.  6. 28.  2. 20. 20.], decoded: []\n",
      "origin: [ 1.  0.  0. 16. 21. 20.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 24.2889 - val_loss: 24.5053\n",
      "origin: [14. 20. 13. 19. 21. 18.], decoded: []\n",
      "origin: [12.  6. 32. 31.  4. 16.], decoded: []\n",
      "origin: [ 6.  3. 35. 34. 25. 12.], decoded: []\n",
      "origin: [ 7. 18. 34. 24.  4. 15.], decoded: []\n",
      "origin: [ 5. 25. 18. 23. 27. 31.], decoded: []\n",
      "origin: [14.  4. 29. 24. 35.  5.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 33s 272ms/step - loss: 24.2831 - val_loss: 24.5042\n",
      "origin: [25. 35. 34. 24. 20. 34.], decoded: []\n",
      "origin: [25. 11. 29. 10.  3. 11.], decoded: []\n",
      "origin: [10. 19. 29. 18.  2.  3.], decoded: []\n",
      "origin: [ 0. 34. 14. 25.  6. 29.], decoded: []\n",
      "origin: [28. 34. 27.  2. 18. 18.], decoded: []\n",
      "origin: [10.  7. 33. 33. 15.  4.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 33s 272ms/step - loss: 24.2616 - val_loss: 24.4744\n",
      "origin: [ 1.  7.  1. 34. 33. 18.], decoded: []\n",
      "origin: [15. 33. 23. 21. 22. 31.], decoded: []\n",
      "origin: [ 6. 30. 28. 28.  0. 21.], decoded: []\n",
      "origin: [ 7.  0. 23.  5. 17. 16.], decoded: []\n",
      "origin: [28.  2. 23. 18. 28. 33.], decoded: []\n",
      "origin: [32.  4.  7. 33. 11. 24.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 33s 272ms/step - loss: 24.2331 - val_loss: 24.4786\n",
      "origin: [ 5. 31.  6.  4. 25. 25.], decoded: []\n",
      "origin: [14. 15. 14. 24. 34. 13.], decoded: []\n",
      "origin: [31.  9.  6. 10. 20. 14.], decoded: []\n",
      "origin: [23.  4. 20.  7. 24. 15.], decoded: []\n",
      "origin: [ 1.  4. 12. 16. 30. 20.], decoded: []\n",
      "origin: [ 6. 16.  4. 11. 20. 18.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 33s 271ms/step - loss: 24.2149 - val_loss: 24.4235\n",
      "origin: [20. 22.  1. 17. 15. 28.], decoded: []\n",
      "origin: [31.  4. 17. 25. 13. 10.], decoded: []\n",
      "origin: [34. 13.  3. 24.  4. 15.], decoded: []\n",
      "origin: [10.  0. 11. 15. 35.  2.], decoded: []\n",
      "origin: [28. 17. 28. 17.  0. 21.], decoded: []\n",
      "origin: [ 3. 34. 30.  7. 22. 10.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 35s 292ms/step - loss: 24.2128 - val_loss: 24.4240\n",
      "origin: [12. 24. 22. 10.  9. 10.], decoded: []\n",
      "origin: [ 2. 24.  9. 24. 30. 34.], decoded: []\n",
      "origin: [22. 12. 20.  2. 24. 30.], decoded: []\n",
      "origin: [ 3.  0.  6. 35. 11.  8.], decoded: []\n",
      "origin: [35. 17. 30. 11.  9. 24.], decoded: []\n",
      "origin: [16. 24. 27. 32. 10. 10.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 33s 272ms/step - loss: 24.1940 - val_loss: 24.3942\n",
      "origin: [33. 35. 24. 12.  1. 16.], decoded: []\n",
      "origin: [11. 35.  9.  5. 18. 24.], decoded: []\n",
      "origin: [ 1. 27. 27.  0. 22.  9.], decoded: []\n",
      "origin: [ 5. 12.  6. 35.  2. 19.], decoded: []\n",
      "origin: [10. 12. 23. 30. 20.  0.], decoded: []\n",
      "origin: [21. 34. 16. 31. 16. 29.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 35s 291ms/step - loss: 24.1745 - val_loss: 24.3502\n",
      "origin: [24. 18. 11. 29.  7. 12.], decoded: []\n",
      "origin: [12. 20.  3.  2. 19. 32.], decoded: []\n",
      "origin: [30. 29. 31.  9. 24.  4.], decoded: []\n",
      "origin: [11. 19.  3.  9. 22.  0.], decoded: []\n",
      "origin: [34. 25. 14. 10. 17.  3.], decoded: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: [11.  5. 15. 22. 35. 10.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 34s 279ms/step - loss: 24.1485 - val_loss: 24.3384\n",
      "origin: [28. 21. 24. 23. 31.  1.], decoded: []\n",
      "origin: [16. 15.  4. 29. 24. 10.], decoded: []\n",
      "origin: [32. 22.  0. 11. 23. 29.], decoded: []\n",
      "origin: [35. 32. 15. 14. 12.  7.], decoded: []\n",
      "origin: [ 1. 16.  0. 32. 27.  0.], decoded: []\n",
      "origin: [21. 34. 16. 31. 16. 29.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 24.1388 - val_loss: 24.3235\n",
      "origin: [ 1.  2. 33. 30. 30.  0.], decoded: []\n",
      "origin: [21.  0. 19. 11. 24.  9.], decoded: []\n",
      "origin: [10.  9. 35. 30. 20. 23.], decoded: []\n",
      "origin: [25. 29. 11.  1. 15. 29.], decoded: []\n",
      "origin: [ 9. 34.  6. 22. 15. 28.], decoded: []\n",
      "origin: [24. 12. 24. 20.  5. 22.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 24.1286 - val_loss: 24.3399\n",
      "origin: [31.  8. 13. 32. 13. 12.], decoded: []\n",
      "origin: [10.  0. 11. 15. 35.  2.], decoded: []\n",
      "origin: [28. 16. 31. 28.  8. 30.], decoded: []\n",
      "origin: [27. 16.  7. 15. 16. 29.], decoded: []\n",
      "origin: [19. 21. 13. 15. 33.  1.], decoded: []\n",
      "origin: [33.  4.  4. 10. 24.  3.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 33s 272ms/step - loss: 24.0941 - val_loss: 24.1919\n",
      "origin: [14. 32. 33. 34.  9. 32.], decoded: []\n",
      "origin: [ 5. 27. 23. 20.  4.  1.], decoded: []\n",
      "origin: [21.  3. 35. 35.  1. 23.], decoded: []\n",
      "origin: [23. 25. 13.  6. 28. 17.], decoded: []\n",
      "origin: [ 6. 22.  2. 11. 19.  2.], decoded: []\n",
      "origin: [19. 28.  9. 30.  6. 24.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 33s 277ms/step - loss: 24.0462 - val_loss: 23.9694\n",
      "origin: [17. 21.  6.  9.  9. 16.], decoded: []\n",
      "origin: [25. 13. 32.  5. 14. 35.], decoded: []\n",
      "origin: [28. 33. 24.  9. 19.  3.], decoded: []\n",
      "origin: [22. 25. 30. 34.  5. 20.], decoded: []\n",
      "origin: [16.  6.  0.  0. 18. 31.], decoded: []\n",
      "origin: [32. 24. 14. 24. 35. 33.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 33s 277ms/step - loss: 23.7100 - val_loss: 23.6362\n",
      "origin: [11.  1. 32.  2.  1.  9.], decoded: []\n",
      "origin: [ 0.  6. 14. 15.  1. 19.], decoded: []\n",
      "origin: [29. 24. 20. 14. 24. 29.], decoded: []\n",
      "origin: [16. 20.  8. 16. 29.  7.], decoded: []\n",
      "origin: [ 0. 25. 12. 30. 17. 23.], decoded: []\n",
      "origin: [ 5. 20. 24. 34.  6.  1.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 33s 277ms/step - loss: 23.6192 - val_loss: 23.6082\n",
      "origin: [ 9. 23.  6.  9. 20. 11.], decoded: []\n",
      "origin: [ 4.  0. 18. 19. 22.  7.], decoded: []\n",
      "origin: [15. 33. 14. 25. 12. 17.], decoded: []\n",
      "origin: [21. 11. 33. 35. 32.  9.], decoded: []\n",
      "origin: [22. 25.  3.  6. 34. 17.], decoded: []\n",
      "origin: [ 2. 33. 30. 28. 20.  7.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 23.5923 - val_loss: 23.6091\n",
      "origin: [ 0. 33. 11. 28. 19.  1.], decoded: []\n",
      "origin: [30. 14. 12. 28.  8. 21.], decoded: []\n",
      "origin: [32. 13.  8. 15.  4.  1.], decoded: []\n",
      "origin: [35. 24. 32. 34. 24. 22.], decoded: []\n",
      "origin: [24.  5. 32. 32. 10. 17.], decoded: []\n",
      "origin: [23.  4. 20.  7. 24. 15.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 23.5773 - val_loss: 23.5998\n",
      "origin: [10. 18. 21.  1. 23. 32.], decoded: []\n",
      "origin: [18. 23. 22. 21.  3.  5.], decoded: []\n",
      "origin: [ 6. 15. 33. 12. 13. 29.], decoded: []\n",
      "origin: [28. 30. 18. 29. 17. 23.], decoded: []\n",
      "origin: [ 2. 31. 27.  3.  7. 25.], decoded: []\n",
      "origin: [ 8. 19. 20.  1.  5. 14.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 33s 278ms/step - loss: 23.5567 - val_loss: 23.5806\n",
      "origin: [23. 21. 22. 25. 25.  5.], decoded: []\n",
      "origin: [ 6. 34. 24. 19. 27.  6.], decoded: []\n",
      "origin: [ 1. 22.  4.  1.  0.  6.], decoded: []\n",
      "origin: [ 8. 34.  5.  9.  8. 29.], decoded: []\n",
      "origin: [27. 28. 21.  7. 25. 28.], decoded: []\n",
      "origin: [ 3. 28.  3. 23. 29. 10.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 32s 270ms/step - loss: 23.5527 - val_loss: 23.5800\n",
      "origin: [30. 12. 21. 21. 35.  7.], decoded: []\n",
      "origin: [25.  3.  5.  9. 11.  6.], decoded: []\n",
      "origin: [29. 33.  5.  5.  3. 11.], decoded: []\n",
      "origin: [31. 13. 35. 29. 35. 14.], decoded: []\n",
      "origin: [24. 16. 19. 19.  7. 33.], decoded: []\n",
      "origin: [ 0. 32. 24. 20. 27. 22.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 33s 275ms/step - loss: 23.5423 - val_loss: 23.5650\n",
      "origin: [22. 14. 23. 18. 17. 23.], decoded: []\n",
      "origin: [28.  1.  6. 33. 34.  7.], decoded: []\n",
      "origin: [ 7. 28. 16.  3. 19. 24.], decoded: []\n",
      "origin: [25. 27. 35.  1. 22. 34.], decoded: []\n",
      "origin: [35.  2. 31. 28. 22. 29.], decoded: []\n",
      "origin: [20.  6. 33. 27. 35. 14.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 33s 278ms/step - loss: 23.5353 - val_loss: 23.5867\n",
      "origin: [34.  6. 29.  8. 30.  7.], decoded: []\n",
      "origin: [ 7. 17. 24.  8.  5. 22.], decoded: []\n",
      "origin: [13. 35. 29. 15. 30. 22.], decoded: []\n",
      "origin: [ 9.  7.  7. 32. 27. 29.], decoded: []\n",
      "origin: [17. 16. 23. 14. 25. 20.], decoded: []\n",
      "origin: [11. 11. 21. 30. 28.  4.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 23.5238 - val_loss: 23.5466\n",
      "origin: [ 1.  9. 15.  3.  3. 12.], decoded: []\n",
      "origin: [ 8. 22.  3. 13.  8. 11.], decoded: []\n",
      "origin: [ 5. 32. 18. 21. 21. 30.], decoded: []\n",
      "origin: [30. 34. 13. 13. 30. 21.], decoded: []\n",
      "origin: [34.  0. 24.  4.  4. 24.], decoded: []\n",
      "origin: [25. 31. 24. 35. 17.  5.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 34s 280ms/step - loss: 23.5213 - val_loss: 23.5580\n",
      "origin: [16. 19. 22.  0.  5. 21.], decoded: []\n",
      "origin: [10. 31. 27.  3. 10. 21.], decoded: []\n",
      "origin: [30.  6. 16. 15. 22. 32.], decoded: []\n",
      "origin: [32. 24. 14. 24. 35. 33.], decoded: []\n",
      "origin: [ 9. 24.  6. 15.  4. 33.], decoded: []\n",
      "origin: [13. 10. 15. 21.  0. 22.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 33s 278ms/step - loss: 23.5205 - val_loss: 23.5513\n",
      "origin: [29.  6. 10.  7.  6. 14.], decoded: []\n",
      "origin: [ 8.  3.  1.  4. 25.  8.], decoded: []\n",
      "origin: [24. 28. 27. 34. 15. 16.], decoded: []\n",
      "origin: [ 3. 25. 30. 29. 23.  6.], decoded: []\n",
      "origin: [32. 24.  6.  3. 24.  4.], decoded: []\n",
      "origin: [30. 32. 24.  5. 30. 29.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 23.5197 - val_loss: 23.5608\n",
      "origin: [23.  4.  7. 22. 30. 30.], decoded: []\n",
      "origin: [32. 16. 11.  9. 33.  8.], decoded: []\n",
      "origin: [ 6.  1.  4. 28. 28. 33.], decoded: []\n",
      "origin: [18. 27.  0. 24. 17.  3.], decoded: []\n",
      "origin: [23.  1. 17.  0. 11. 12.], decoded: []\n",
      "origin: [31. 29. 35.  0.  1. 31.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 34s 280ms/step - loss: 23.5152 - val_loss: 23.5563\n",
      "origin: [32.  3. 32.  3. 12. 33.], decoded: []\n",
      "origin: [ 2. 34.  3.  6.  4.  9.], decoded: []\n",
      "origin: [ 1. 32. 22. 24. 35.  3.], decoded: []\n",
      "origin: [17. 20. 35. 24. 34. 25.], decoded: []\n",
      "origin: [27. 23. 12. 25. 31. 27.], decoded: []\n",
      "origin: [16. 35.  2. 22. 22. 24.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 23.5112 - val_loss: 23.5473\n",
      "origin: [ 1. 24. 12. 29. 20. 29.], decoded: []\n",
      "origin: [28. 27. 19.  4. 31. 22.], decoded: []\n",
      "origin: [ 0. 21. 24. 21. 35. 11.], decoded: []\n",
      "origin: [ 4.  9. 15.  6. 23. 34.], decoded: []\n",
      "origin: [ 7. 35. 12. 32. 28.  1.], decoded: []\n",
      "origin: [ 3.  8. 18.  2. 20. 20.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 33s 272ms/step - loss: 23.5103 - val_loss: 23.5385\n",
      "origin: [19.  4. 11.  5.  4.  8.], decoded: []\n",
      "origin: [ 8. 27. 15. 24. 12. 12.], decoded: []\n",
      "origin: [32. 28. 32.  6. 14.  4.], decoded: []\n",
      "origin: [22. 11. 33. 24. 35. 12.], decoded: []\n",
      "origin: [ 3. 32. 24. 25. 22.  4.], decoded: []\n",
      "origin: [ 8. 20.  9. 25.  5.  4.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 33s 274ms/step - loss: 23.5069 - val_loss: 23.5344\n",
      "origin: [35.  2.  2. 24. 13.  9.], decoded: []\n",
      "origin: [13. 15. 31. 20. 14.  0.], decoded: []\n",
      "origin: [17. 29.  5. 11. 33. 10.], decoded: []\n",
      "origin: [ 0. 23. 24.  2. 29. 21.], decoded: []\n",
      "origin: [ 5. 34. 30.  3.  1. 19.], decoded: []\n",
      "origin: [ 2. 34. 31.  5. 22. 21.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 23.5024 - val_loss: 23.5429\n",
      "origin: [34.  4.  5. 10.  6.  5.], decoded: []\n",
      "origin: [34. 34. 30. 13.  2. 14.], decoded: []\n",
      "origin: [33. 35.  1.  0. 29. 20.], decoded: []\n",
      "origin: [ 6.  7.  7. 29. 32. 19.], decoded: []\n",
      "origin: [ 7. 27. 18. 32. 14. 25.], decoded: []\n",
      "origin: [14.  0.  5. 29.  3. 17.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 40s 329ms/step - loss: 23.5019 - val_loss: 23.5433\n",
      "origin: [15. 17. 25. 14.  7. 33.], decoded: []\n",
      "origin: [20. 33. 16.  3.  0.  8.], decoded: []\n",
      "origin: [24.  8. 10. 17.  0. 22.], decoded: []\n",
      "origin: [28.  9. 31.  3. 22. 18.], decoded: []\n",
      "origin: [ 7. 12. 10.  1. 27. 31.], decoded: []\n",
      "origin: [29.  9. 19.  8. 22. 28.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 33s 276ms/step - loss: 23.5014 - val_loss: 23.5574\n",
      "origin: [19. 25. 13. 24.  1. 18.], decoded: []\n",
      "origin: [12. 27. 21.  5.  3.  1.], decoded: []\n",
      "origin: [29.  6. 10. 15.  2. 24.], decoded: []\n",
      "origin: [ 1. 10. 27. 34. 25. 24.], decoded: []\n",
      "origin: [ 3.  9.  6. 35.  5. 33.], decoded: []\n",
      "origin: [ 7. 19. 23.  6. 21. 25.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 32s 270ms/step - loss: 23.5010 - val_loss: 23.5570\n",
      "origin: [29. 31. 10. 28.  2. 27.], decoded: []\n",
      "origin: [ 0. 21. 29.  8. 28.  5.], decoded: []\n",
      "origin: [ 6.  7. 27. 22. 19. 34.], decoded: []\n",
      "origin: [25. 17. 22. 31. 30.  4.], decoded: []\n",
      "origin: [31. 18.  9. 12.  5.  7.], decoded: []\n",
      "origin: [ 5. 10. 27. 11.  7.  3.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 23.5007 - val_loss: 23.5505\n",
      "origin: [25. 10. 32. 11.  6. 25.], decoded: []\n",
      "origin: [15.  5. 20. 27. 10. 14.], decoded: []\n",
      "origin: [22. 28. 17.  7. 27. 34.], decoded: []\n",
      "origin: [27. 23. 10. 23. 34. 28.], decoded: []\n",
      "origin: [33. 30.  8. 10. 22.  5.], decoded: []\n",
      "origin: [18. 31. 17. 30. 34.  7.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 32s 271ms/step - loss: 23.5004 - val_loss: 23.5456\n",
      "origin: [30.  9. 19. 20. 29. 29.], decoded: []\n",
      "origin: [ 8. 34. 11.  8.  3. 30.], decoded: []\n",
      "origin: [27. 31. 30.  7.  5. 16.], decoded: []\n",
      "origin: [28. 31. 31. 18. 34. 18.], decoded: []\n",
      "origin: [22.  9. 20. 24. 35. 11.], decoded: []\n",
      "origin: [21.  5.  9.  4. 22. 15.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 35s 289ms/step - loss: 23.5002 - val_loss: 23.5387\n",
      "origin: [ 3.  6.  4. 10.  1. 17.], decoded: []\n",
      "origin: [ 0.  6. 14. 15.  1. 19.], decoded: []\n",
      "origin: [31. 20. 18. 20.  9. 18.], decoded: []\n",
      "origin: [ 6. 20. 17.  8. 24. 30.], decoded: []\n",
      "origin: [32. 28. 20.  8. 16. 24.], decoded: []\n",
      "origin: [24. 20. 18.  3. 16. 35.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 32s 269ms/step - loss: 23.5000 - val_loss: 23.5346\n",
      "origin: [34. 32. 15. 18.  2.  4.], decoded: []\n",
      "origin: [11. 25. 12.  8.  2.  3.], decoded: []\n",
      "origin: [27.  6. 27. 14.  8. 35.], decoded: []\n",
      "origin: [19.  8. 24.  3. 20. 12.], decoded: []\n",
      "origin: [ 1. 15. 20. 32. 31. 30.], decoded: []\n",
      "origin: [25.  2. 14. 18. 31.  6.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 23.4996 - val_loss: 23.5390\n",
      "origin: [25. 20.  4. 29.  9. 24.], decoded: []\n",
      "origin: [11.  7. 22. 34. 24. 19.], decoded: []\n",
      "origin: [22.  9. 24. 28. 25.  7.], decoded: []\n",
      "origin: [32. 25. 35.  7.  7. 24.], decoded: []\n",
      "origin: [25. 35.  1.  0. 19. 28.], decoded: []\n",
      "origin: [18.  8. 19.  8.  6. 10.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 33s 278ms/step - loss: 23.4992 - val_loss: 23.5372\n",
      "origin: [ 6. 21. 34. 23. 23. 19.], decoded: []\n",
      "origin: [ 5. 27. 14. 27. 11. 29.], decoded: []\n",
      "origin: [29. 20. 32. 15.  2. 31.], decoded: []\n",
      "origin: [35. 17.  4. 27. 24. 13.], decoded: []\n",
      "origin: [10. 18. 30. 11. 11.  1.], decoded: []\n",
      "origin: [11.  4. 21.  4. 10.  6.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 87s 721ms/step - loss: 23.4966 - val_loss: 23.5308\n",
      "origin: [31. 13. 19. 22. 19.  1.], decoded: []\n",
      "origin: [ 2. 30.  1. 22. 17. 35.], decoded: []\n",
      "origin: [ 6. 31. 24. 17. 32.  5.], decoded: []\n",
      "origin: [24. 28. 24. 17. 32. 18.], decoded: []\n",
      "origin: [ 8. 29.  5. 20. 11. 11.], decoded: []\n",
      "origin: [ 2. 30. 17. 15. 30. 18.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 118s 981ms/step - loss: 23.4906 - val_loss: 23.5383\n",
      "origin: [ 9. 24.  0. 32. 29. 21.], decoded: []\n",
      "origin: [25. 12.  6. 15. 17. 20.], decoded: []\n",
      "origin: [15.  2. 14.  1.  7. 21.], decoded: []\n",
      "origin: [24. 35.  4. 20. 29. 17.], decoded: []\n",
      "origin: [29.  0.  3.  0. 25.  1.], decoded: []\n",
      "origin: [33.  6.  0. 35.  1.  4.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 55s 456ms/step - loss: 23.4905 - val_loss: 23.5375\n",
      "origin: [ 3.  0. 35.  0. 33. 16.], decoded: []\n",
      "origin: [ 2. 27. 10. 29. 13. 24.], decoded: []\n",
      "origin: [10. 22. 27. 30.  1. 35.], decoded: []\n",
      "origin: [ 0. 19. 13. 34. 33. 15.], decoded: []\n",
      "origin: [24. 27.  2. 24. 29. 30.], decoded: []\n",
      "origin: [23.  4.  3. 29. 25.  9.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 62s 514ms/step - loss: 23.4903 - val_loss: 23.5413\n",
      "origin: [27. 23. 18. 24. 28. 11.], decoded: []\n",
      "origin: [ 0. 24.  8. 19. 22.  9.], decoded: []\n",
      "origin: [25. 33. 35.  5.  9. 31.], decoded: []\n",
      "origin: [ 8. 24. 24. 22. 30. 15.], decoded: []\n",
      "origin: [ 1. 27.  7. 35. 27.  9.], decoded: []\n",
      "origin: [ 0. 29. 15. 14. 11. 20.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 125s 1s/step - loss: 23.4901 - val_loss: 23.5324\n",
      "origin: [ 7. 20. 15. 32.  6. 27.], decoded: []\n",
      "origin: [28. 29.  9. 34. 12. 33.], decoded: []\n",
      "origin: [24.  3. 28. 24. 27. 15.], decoded: []\n",
      "origin: [ 1. 11. 30.  1.  8. 18.], decoded: []\n",
      "origin: [21.  8. 18.  5. 19.  0.], decoded: []\n",
      "origin: [14. 13. 14. 32. 24. 28.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 68s 567ms/step - loss: 23.4898 - val_loss: 23.5462\n",
      "origin: [24.  7.  5. 19. 22. 34.], decoded: []\n",
      "origin: [31. 25.  1. 21. 32. 28.], decoded: []\n",
      "origin: [25. 11. 29. 10.  3. 11.], decoded: []\n",
      "origin: [ 1.  2. 14. 13. 27. 13.], decoded: []\n",
      "origin: [ 9. 24.  6. 15.  4. 33.], decoded: []\n",
      "origin: [25. 35.  7. 29.  3. 13.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 49s 410ms/step - loss: 23.4888 - val_loss: 23.5962\n",
      "origin: [19. 16. 13. 35. 18.  6.], decoded: []\n",
      "origin: [27. 24.  1.  8. 23. 28.], decoded: []\n",
      "origin: [ 0. 27. 24. 15. 11. 21.], decoded: []\n",
      "origin: [18.  0. 24. 14. 28.  6.], decoded: []\n",
      "origin: [23. 33. 29. 13. 33. 14.], decoded: []\n",
      "origin: [ 8.  2.  3. 15.  8. 34.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 116s 963ms/step - loss: 23.4897 - val_loss: 23.5463\n",
      "origin: [11. 16.  7. 24.  5. 19.], decoded: []\n",
      "origin: [30. 28. 28.  3. 19. 17.], decoded: []\n",
      "origin: [29. 27.  3. 24. 22.  5.], decoded: []\n",
      "origin: [25. 23.  3. 15.  5. 15.], decoded: []\n",
      "origin: [ 4.  2. 34. 23. 21. 35.], decoded: []\n",
      "origin: [23.  1. 17.  0. 11. 12.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 69s 575ms/step - loss: 24.2140 - val_loss: 23.7678\n",
      "origin: [24. 18. 11. 29.  7. 12.], decoded: []\n",
      "origin: [ 1. 34. 12.  6. 27. 20.], decoded: []\n",
      "origin: [12. 34. 24. 21. 12. 30.], decoded: []\n",
      "origin: [23. 19. 14. 25. 13.  1.], decoded: []\n",
      "origin: [31. 12. 14.  9. 30.  9.], decoded: []\n",
      "origin: [32. 12. 35.  5. 12. 33.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 52s 432ms/step - loss: 23.7935 - val_loss: 23.8173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: [ 3.  4. 28.  9. 29. 34.], decoded: []\n",
      "origin: [ 1.  5. 17. 25. 32. 28.], decoded: []\n",
      "origin: [35.  7.  4. 16. 24. 15.], decoded: []\n",
      "origin: [ 5. 34.  0. 25. 31. 22.], decoded: []\n",
      "origin: [29.  6.  6. 18. 14.  8.], decoded: []\n",
      "origin: [32. 16. 21. 24. 35.  8.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 122s 1s/step - loss: 23.7804 - val_loss: 23.8330\n",
      "origin: [14.  3. 24.  1. 19.  4.], decoded: []\n",
      "origin: [11. 32.  3.  3. 27. 18.], decoded: []\n",
      "origin: [11. 25.  8.  8. 12. 21.], decoded: []\n",
      "origin: [12.  0.  9.  3. 24.  5.], decoded: []\n",
      "origin: [ 6. 10. 14. 18.  3. 24.], decoded: []\n",
      "origin: [27.  3. 27.  5.  1. 32.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 58s 480ms/step - loss: 23.7792 - val_loss: 23.8311\n",
      "origin: [ 3. 23.  3. 24. 17.  0.], decoded: []\n",
      "origin: [24.  2. 35. 24.  4. 32.], decoded: []\n",
      "origin: [ 8. 19. 12. 21.  7. 29.], decoded: []\n",
      "origin: [ 2.  1.  3.  4. 33. 24.], decoded: []\n",
      "origin: [30. 13. 14.  9. 19. 24.], decoded: []\n",
      "origin: [ 8. 33. 15. 25. 34. 32.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 77s 642ms/step - loss: 23.7780 - val_loss: 23.8421\n",
      "origin: [30. 12. 19. 25.  5. 11.], decoded: []\n",
      "origin: [30. 13. 14.  3. 21. 23.], decoded: []\n",
      "origin: [31. 25. 17.  7. 27.  8.], decoded: []\n",
      "origin: [17. 16. 17. 29.  4.  5.], decoded: []\n",
      "origin: [23. 24.  4. 15. 24. 22.], decoded: []\n",
      "origin: [ 8. 33. 22. 19. 23.  3.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 97s 812ms/step - loss: 23.7725 - val_loss: 23.8387\n",
      "origin: [13. 19. 12.  8. 35. 29.], decoded: []\n",
      "origin: [32. 17. 16. 10. 10. 25.], decoded: []\n",
      "origin: [17. 21.  7.  8.  3. 22.], decoded: []\n",
      "origin: [ 3.  8. 14.  0. 24.  0.], decoded: []\n",
      "origin: [17. 18. 30.  6. 10.  1.], decoded: []\n",
      "origin: [24. 11. 31. 14.  7.  9.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 39s 323ms/step - loss: 23.7666 - val_loss: 23.8534\n",
      "origin: [ 9. 23. 13. 32.  5.  8.], decoded: []\n",
      "origin: [ 2.  3.  3. 23. 23. 19.], decoded: []\n",
      "origin: [14.  6. 17. 33. 24. 27.], decoded: []\n",
      "origin: [24.  8. 15. 10. 23. 11.], decoded: []\n",
      "origin: [10. 14. 10. 21. 24.  9.], decoded: []\n",
      "origin: [28.  8. 24.  8. 24. 32.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 124s 1s/step - loss: 23.7602 - val_loss: 23.8229\n",
      "origin: [ 7. 24. 24.  5. 35. 27.], decoded: []\n",
      "origin: [15.  4. 22. 19.  0. 20.], decoded: []\n",
      "origin: [10.  0.  2. 16. 18. 31.], decoded: []\n",
      "origin: [28. 19. 13.  6. 32.  6.], decoded: []\n",
      "origin: [16. 28.  7. 24.  1. 16.], decoded: []\n",
      "origin: [10. 18. 21.  0. 16.  6.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 38s 314ms/step - loss: 23.7463 - val_loss: 23.8241\n",
      "origin: [ 2.  3. 16.  9. 25.  3.], decoded: []\n",
      "origin: [24.  6. 14. 31. 24.  5.], decoded: []\n",
      "origin: [35. 28. 21.  0. 20. 32.], decoded: []\n",
      "origin: [20. 25. 34. 24. 14.  0.], decoded: []\n",
      "origin: [ 1. 30. 22. 18. 35.  5.], decoded: []\n",
      "origin: [10. 30. 13.  5.  7. 27.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 103s 859ms/step - loss: 23.7456 - val_loss: 23.8204\n",
      "origin: [28. 22.  5.  0.  5. 34.], decoded: []\n",
      "origin: [ 8.  8. 31. 19.  3. 34.], decoded: []\n",
      "origin: [25. 24. 24.  8. 10. 22.], decoded: []\n",
      "origin: [11. 13. 20.  7.  1.  3.], decoded: []\n",
      "origin: [ 7.  0. 19. 29.  6. 14.], decoded: []\n",
      "origin: [21. 28.  6. 28. 33. 22.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 56s 466ms/step - loss: 23.7452 - val_loss: 23.8171\n",
      "origin: [ 4. 28. 24.  9. 13. 12.], decoded: []\n",
      "origin: [19. 11. 19. 27. 23.  6.], decoded: []\n",
      "origin: [ 3.  2. 19. 23.  8.  8.], decoded: []\n",
      "origin: [19. 24.  7.  1. 22. 29.], decoded: []\n",
      "origin: [30. 14. 12. 28.  8. 21.], decoded: []\n",
      "origin: [30. 11.  2. 17. 35. 16.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 93s 771ms/step - loss: 23.7448 - val_loss: 23.8190\n",
      "origin: [ 4. 32. 24. 28.  1.  0.], decoded: []\n",
      "origin: [28. 31. 28. 24. 15. 24.], decoded: []\n",
      "origin: [23. 17. 22. 23. 23. 25.], decoded: []\n",
      "origin: [25.  3.  5.  9. 11.  6.], decoded: []\n",
      "origin: [24. 15. 24.  6. 28. 10.], decoded: []\n",
      "origin: [ 4.  8.  1. 30.  1.  8.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 64s 533ms/step - loss: 23.7443 - val_loss: 23.8269\n",
      "origin: [ 8.  8. 34. 34. 15.  1.], decoded: []\n",
      "origin: [33. 22. 29. 14. 25.  3.], decoded: []\n",
      "origin: [15. 11. 15.  9. 32. 14.], decoded: []\n",
      "origin: [15. 11. 28. 19. 19.  2.], decoded: []\n",
      "origin: [35.  4.  7. 24.  5. 21.], decoded: []\n",
      "origin: [33. 11. 21. 32. 20.  3.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 85s 706ms/step - loss: 23.7438 - val_loss: 23.8157\n",
      "origin: [ 2. 21. 20. 13. 33. 10.], decoded: []\n",
      "origin: [32. 15.  6. 28. 11. 15.], decoded: []\n",
      "origin: [15. 33.  0. 11. 17.  3.], decoded: []\n",
      "origin: [10.  0. 24. 28. 29. 31.], decoded: []\n",
      "origin: [24. 31.  4. 22. 13.  4.], decoded: []\n",
      "origin: [31.  5.  1. 32. 31. 23.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 63s 523ms/step - loss: 23.7433 - val_loss: 23.8184\n",
      "origin: [ 1.  7. 35. 34. 16.  9.], decoded: []\n",
      "origin: [20. 29. 24. 21.  6. 11.], decoded: []\n",
      "origin: [10. 27. 23.  9.  9.  9.], decoded: []\n",
      "origin: [30. 14. 12. 28.  8. 21.], decoded: []\n",
      "origin: [34.  2. 27. 34. 15.  2.], decoded: []\n",
      "origin: [ 3. 22. 13. 20. 34. 22.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 80s 670ms/step - loss: 23.7430 - val_loss: 23.8167\n",
      "origin: [ 9. 19. 19.  4. 24. 29.], decoded: []\n",
      "origin: [10. 18. 21.  0. 16.  6.], decoded: []\n",
      "origin: [ 0.  5. 22.  1. 12.  9.], decoded: []\n",
      "origin: [ 8. 12.  2. 20. 22. 27.], decoded: []\n",
      "origin: [29. 21.  1. 28. 25. 24.], decoded: []\n",
      "origin: [12. 25. 23. 11.  9. 13.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 66s 548ms/step - loss: 23.7430 - val_loss: 23.8199\n",
      "origin: [24. 18. 11.  1.  7.  6.], decoded: []\n",
      "origin: [35.  3. 23. 23. 13. 12.], decoded: []\n",
      "origin: [14. 24. 29. 23.  1. 24.], decoded: []\n",
      "origin: [29. 16. 19. 23. 24. 21.], decoded: []\n",
      "origin: [28. 18. 18. 17. 15. 33.], decoded: []\n",
      "origin: [ 6.  8. 19. 18.  6. 17.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 82s 681ms/step - loss: 23.7431 - val_loss: 23.8221\n",
      "origin: [24. 20. 16. 11.  5. 16.], decoded: []\n",
      "origin: [34. 14.  1.  5.  3. 30.], decoded: []\n",
      "origin: [12. 35. 12. 34. 19. 25.], decoded: []\n",
      "origin: [14. 23. 23. 29. 18.  1.], decoded: []\n",
      "origin: [34. 11. 34. 23.  1. 18.], decoded: []\n",
      "origin: [ 1.  7. 33. 27.  9. 12.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 61s 511ms/step - loss: 23.7432 - val_loss: 23.8144\n",
      "origin: [ 5.  9. 14. 25. 25. 18.], decoded: []\n",
      "origin: [ 9. 11. 16. 35.  1.  6.], decoded: []\n",
      "origin: [16.  4.  0.  8. 29. 15.], decoded: []\n",
      "origin: [14. 32. 27. 20. 34.  3.], decoded: []\n",
      "origin: [ 3.  0. 35.  0. 33. 16.], decoded: []\n",
      "origin: [ 6. 11. 33. 31. 35.  8.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 89s 739ms/step - loss: 23.7433 - val_loss: 23.8223\n",
      "origin: [11. 31.  5.  8. 35. 23.], decoded: []\n",
      "origin: [ 9.  4. 22.  1.  3. 31.], decoded: []\n",
      "origin: [21. 22. 29. 21. 14. 16.], decoded: []\n",
      "origin: [23. 16.  3. 13. 19.  0.], decoded: []\n",
      "origin: [ 2.  9. 32. 30.  1. 19.], decoded: []\n",
      "origin: [19. 34. 16.  2. 10. 23.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 42s 351ms/step - loss: 23.7432 - val_loss: 23.8260\n",
      "origin: [20. 32. 12.  3. 24.  1.], decoded: []\n",
      "origin: [32. 24. 14. 24. 35. 33.], decoded: []\n",
      "origin: [ 1. 35. 35.  9. 27. 24.], decoded: []\n",
      "origin: [ 8. 19. 12. 21.  7. 29.], decoded: []\n",
      "origin: [ 6. 19. 31.  2.  0. 17.], decoded: []\n",
      "origin: [29. 19. 12. 35. 33.  2.], decoded: []\n",
      "\n",
      "acc: 0.000000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b385e6160>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "# captures output of softmax so we can decode the output during visualization\n",
    "test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "viz_cb = VizCallback(datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S'), test_func, img_gen.get_next_val())\n",
    "model.fit_generator(generator=img_gen.get_next_train(100),\n",
    "                    steps_per_epoch=120,\n",
    "                    epochs=100,\n",
    "                    validation_data=img_gen.get_next_val(1000),\n",
    "                    validation_steps=5,\n",
    "                    callbacks=[evaluator,],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 60, 1)\n",
      "(60, 200, 1)\n",
      "(60, 200)\n",
      "230.0\n",
      "30.0\n",
      "(12000,)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bc9d71c2b8a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hwc->whc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2699\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2701\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mE:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5494\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    636\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    637\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 638\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "generator = img_gen.get_next_val(2)\n",
    "_x_input, _  = next(generator)\n",
    "_X_test = _x_input['the_input']\n",
    "_y_test = _x_input['the_labels']\n",
    "\n",
    "img = _X_test[0]\n",
    "print(img.shape)\n",
    "print(np.einsum('hwc->whc', img).shape)\n",
    "print(img[:, :, 0].T.shape)\n",
    "print(np.max(img.flatten()))\n",
    "print(np.min(img.flatten()))\n",
    "print(_X_test[0].flatten().shape)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img[:, :, 0].T)\n",
    "plt.subplot(1, 2, 2)\n",
    "img = np.einsum('hwc->whc', img)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# for i in range(_y_pred.shape[0]):\n",
    "#     _y_pred = base_model.predict(np.expand_dims(_X_test[i], axis=0))[:, 2:, :]\n",
    "#     print(_y_pred.shape)\n",
    "#     for i in range(_y_pred.shape[0]):\n",
    "#         __X_test = _X_test[i]\n",
    "#         __y_test = _y_test[i]\n",
    "#         __y_pred = _y_pred[i]\n",
    "#         __y_pred = np.expand_dims(__y_pred, axis=0)\n",
    "#         shape = __y_pred.shape\n",
    "#         ctc_decode = K.ctc_decode(__y_pred, \n",
    "#                                   input_length=np.ones(shape[0])*shape[1])[0][0]\n",
    "#         out = K.get_value(ctc_decode)[0]\n",
    "#         print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n",
    "from IPython.display import Image\n",
    "Image(filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = './weights/my_model_weights.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-076f3a675f55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./weights/my_model_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite)\u001b[0m\n\u001b[0;32m   1118\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mproceed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m             \u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights_to_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    393\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\scriptpath\\visualstudio\\shared\\Anaconda3_64\\envs\\tfgpu\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = './weights/my_model_weights.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "model.save_weights('./weights/my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
